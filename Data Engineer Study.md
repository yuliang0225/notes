# Data Engineer Study
#Study #data-engineer #data-pipeline #study/datamart
---
## Refers
- [DataExpert-io/data-engineer-handbook: This is a repo with links to everything you'd ever want to learn about data engineering](https://github.com/DataExpert-io/data-engineer-handbook)
- https://github.com/DataTalksClub/data-engineering-zoomcamp
- https://github.com/singgel/BIGDATA_LINE/tree/master
- https://juejin.cn/user/1116759542740206/posts
- https://gist.github.com/leoricklin/f28a27d2fa718f6ef06960718442c859
### Technology stack
- Apache Pulsar
- Spark
- dbt
- Dagster
- Looker
---
## Fundamentals of Data Engineering
- https://soclibrary.futa.edu.ng/books/Fundamentals%20of%20Data%20Engineering%20(Reis,%20JoeHousley,%20Matt)%20(Z-Library).pdf
### CHAPTER 1 Data Engineering Described
- What Is Data Engineering?
  - a data engineer gets data, stores it, and prepares it for consumption by data scientists, analysts, and others.
- 数据工程是指开发、实施和维护系统和流程，将原始数据转化为高质量且一致的信息，以支持下游的使用场景，如数据分析和机器学习。
  - 数据工程位于多个领域的交汇处，包括**安全性**、**数据管理**、**DataOps**、**数据架构**、**编排**和**软件工程**。
  - 数据工程师负责管理数据工程的全生命周期，从从源系统获取数据开始，到最终为分析或机器学习等场景提供数据为止。
- The Data Engineering Lifecycle
  - The stages of the data engineering lifecycle are as follows:
    * Generation
    * Storage
    * Ingestion
    * Transformation
    * Serving
![](Data%20Engineer%20Study/%E6%88%AA%E5%B1%8F2025-03-27%20%E4%B8%8B%E5%8D%881.56.45.png)<!-- {"width":747} -->
- Data Engineering and Data Science
![](Data%20Engineer%20Study/%E6%88%AA%E5%B1%8F2025-03-27%20%E4%B8%8B%E5%8D%882.01.16.png)<!-- {"width":747} -->
![](Data%20Engineer%20Study/%E6%88%AA%E5%B1%8F2025-03-27%20%E4%B8%8B%E5%8D%882.01.33.png)<!-- {"width":747} -->
- Data Engineering Skills and Activities
![](Data%20Engineer%20Study/%E6%88%AA%E5%B1%8F2025-03-27%20%E4%B8%8B%E5%8D%882.02.03.png)<!-- {"width":752} -->
- Data Maturity and the Data Engineer
  - Stage 1: Starting with data
  - Stage 2: Scaling with data
  - Stage 3: Leading with data
- The Background and Skills of a Data Engineer
  - Business Responsibilities
    - Know how to communicate with nontechnical and technical people.
    - Understand how to scope and gather business and product requirements.
    - Understand the cultural foundations of Agile, DevOps, and DataOps.
    - Control costs.
    - Learn continuously.
  - Technical Responsibilities
    * Security
    * Data management
    * DataOps
    * Data architecture
    * Orchestration
    * Software engineering
  * Languages
    * SQL, Python, JVM, bash
    * dbt, cpp
* The Continuum of Data Engineering Roles, from A to B
  * A 型数据工程师
    * **A 代表抽象（Abstraction）**。
    * A 型数据工程师倾向于避免繁重且重复的基础工作，尽量使数据架构保持抽象和简单，并避免重复造轮子。
    * 他们主要通过使用现成的产品、托管服务和工具来管理数据工程生命周期。
    * A 型数据工程师广泛分布于各行各业的公司，且适用于所有数据成熟度水平的企业。
  * B 型数据工程师
    * **B 代表构建（Build）**。
    * B 型数据工程师专注于构建数据工具和系统，以实现可扩展性，并充分发挥公司的核心竞争力和优势。
    * 在数据成熟度模型中，B 型数据工程师通常出现在处于 **第 2 阶段（数据扩展阶段）** 和 **第 3 阶段（数据引领阶段）** 的公司，或者在初始数据应用场景极为独特且对业务至关重要时，需要定制化的数据工具来启动项目。
  * A 型和 B 型数据工程师的协作
    * A 型和 B 型数据工程师可能会在同一家公司工作，甚至可能由同一个人承担这两种角色！
    * 在实践中，企业通常会**先招聘 A 型数据工程师**来搭建基础数据架构。
    * 随着数据需求的增长和公司数据能力的提升，**再引入 B 型数据工程师**来开发定制化的数据解决方案。
* Data Engineers Inside an Organization
![](Data%20Engineer%20Study/%E6%88%AA%E5%B1%8F2025-03-27%20%E4%B8%8B%E5%8D%882.12.53.png)<!-- {"width":752} -->
![](Data%20Engineer%20Study/%E6%88%AA%E5%B1%8F2025-03-27%20%E4%B8%8B%E5%8D%882.13.20.png)<!-- {"width":752} -->
- Data Engineers and Other Technical Roles
![](Data%20Engineer%20Study/%E6%88%AA%E5%B1%8F2025-03-27%20%E4%B8%8B%E5%8D%882.13.43.png)<!-- {"width":752} -->
---
## CHAPTER 2 The Data Engineering Lifecycle
- 数据摄取（Ingestion）
  - 在了解数据源、源系统的特性以及数据的存储方式之后，下一步就是**从源系统中收集数据**。
    - 数据工程生命周期的这一阶段被称为**数据摄取**。
  - 根据我们的经验，**源系统和数据摄取**通常是数据工程生命周期中最主要的瓶颈。
    - 源系统通常不在你的直接控制范围内，可能会**无故变得无响应**，或者提供**质量较差的数据**。
    - 与此同时，你的数据摄取服务也可能因为各种原因**神秘地停止工作**。
  - 这些问题会导致数据流中断，或者导致存储、处理和服务阶段的数据量不足。
- 数据摄取的不稳定性带来的影响
  - 不可靠的源系统和数据摄取服务会在整个数据工程生命周期中产生**连锁反应**。
    - 如果数据摄取失败，后续的存储、处理和使用数据的环节都会受到影响。
  - 不过，如果你在前期阶段已经**充分了解并解决了源系统相关的关键问题**，那么你的数据摄取过程会更加顺利且稳定。
- Batch versus streaming
- Reverse ETL
![](Data%20Engineer%20Study/%E6%88%AA%E5%B1%8F2025-03-27%20%E4%B8%8B%E5%8D%882.20.17.png)<!-- {"width":759} -->
- Major Undercurrents Across the Data Engineering Lifecycle
![](Data%20Engineer%20Study/%E6%88%AA%E5%B1%8F2025-03-27%20%E4%B8%8B%E5%8D%882.20.45.png)<!-- {"width":759} -->
- Data accountability. 
  - **数据责任制**意味着为特定的数据部分指定一个负责人，对该数据的管理和治理活动负责。
    - 这个负责人需要协调相关利益方，确保数据治理工作的顺利进行。
  - 如果没有明确的责任人来对数据负责，数据质量的管理将变得非常困难。
  - 数据责任人的角色
    - 值得注意的是，**数据的责任人不一定是数据工程师**。
      * 数据责任人可能是**软件工程师**、**产品经理**，或者担任其他角色的人员。
      * 通常情况下，数据责任人不会拥有维护数据质量所需的全部资源。
      * 相反，他们会协调与数据相关的所有人员，包括数据工程师，共同维护数据质量。
  * 数据责任制的不同层级
    * 数据责任制可以在**不同的层级**上实施：
      * **表级**：某人对一张表中的数据负有责任。
      * **日志流级**：某人负责一组数据流的管理。
      * **字段级**：甚至可以细化到一个跨多张表的单一字段（例如**客户 ID**）。
    - 在企业数据管理中，数据领域（**Data Domain**）指的是某个字段类型可能存在的所有值的集合。
      - 例如，一个客户 ID 的数据领域包括所有可能的客户 ID 值。
  - 看似繁琐但至关重要
    - 虽然这种层级化的数据责任制可能看起来过于官僚且繁琐，但它对**数据质量的提升**具有极大的影响。
    - 明确的责任划分可以确保数据在整个生命周期中得到妥善管理和维护。
- **数据质量（Data Quality）**
  - 数据质量是指将数据优化到理想状态的过程，其核心问题是：
    - **“实际获取的数据与期望的数据是否一致？”**
  - 数据应符合业务元数据中的预期要求。换句话说，数据是否与业务方达成一致的定义相匹配？
    - 在数据工程生命周期中，**数据工程师**的职责是确保数据质量，包括：
      * 执行**数据质量测试**
      * 确保数据符合**数据模式（Schema）**的预期
      * 确保数据的**完整性**
      * 保证数据的**精确性**
  * 数据质量的三个主要特征
    * 根据《数据治理：终极指南》（*Data Governance: The Definitive Guide*），数据质量由以下三个主要特征定义：
      1. **准确性（Accuracy）**
         * 收集的数据是否真实、正确？
         * 数据中是否存在重复值？
         * 数值数据是否精确？
      2. **完整性（Completeness）**
         * 数据记录是否完整？
         * 所有必填字段是否包含有效值？
      3. **时效性（Timeliness）**
         * 数据是否能在需要时及时获取？
  * Master Data Management
    * **主数据**是指关于企业实体的信息，例如**员工**、**客户**、**产品**和**地点**等。
      * 随着企业通过**自然增长**和**并购**等方式不断扩大规模，同时与其他企业进行合作，**保持实体和身份信息的一致性**将变得越来越困难。
    * 什么是主数据管理？
      * **主数据管理（MDM）**是一种用于创建和维护一致的实体定义的实践方式，这种一致的定义通常称为 **黄金记录（Golden Record）**。
      * 黄金记录通过在企业内部以及与合作伙伴之间协调实体数据，确保数据的统一性。
      * MDM 不仅仅是一个技术问题，它是一个**业务运营过程**，并通过构建和部署技术工具来实现。
    * MDM 的职责归属
      * MDM 通常涉及整个数据生命周期，并深入到企业的**运营数据库**中。
      * 它有时会由数据工程团队直接负责，但在许多企业中，MDM 的责任会被分配给一个**专门的团队**，该团队跨部门协作，推动 MDM 的实施。
      * 即使数据工程师不是 MDM 的直接负责人，他们仍然需要了解 MDM 的相关概念和实践。
      * 数据工程师在许多情况下需要与 MDM 团队合作，共同推动数据一致性和质量管理。
---
## CHAPTER 3 Designing Good Data Architecture
- What Is Data Architecture
  - “Good” Data Architecture
    - Never shoot for the best architecture, but rather the least worst architecture.
- 敏捷性：良好数据架构的基础
  - **敏捷性**是良好数据架构的基础，因为它承认世界是不断变化的。
  - 良好的数据架构具备**灵活性**和**易维护性**，能够随着企业的变化、技术的进步以及新的实践方法不断演进。
    - 未来的新技术和新业务需求可能会带来更多的价值，而优秀的数据架构应具备适应这些变化的能力。
  - 企业及其数据的使用场景总是在不断变化的。
    - 去年的数据架构可能在当时表现良好，但它未必能满足今天的需求，更不用说明年了。
- 糟糕的数据架构的特征
  - **不良的数据架构**通常具有以下特点：
    * **紧密耦合**：各个系统之间过于依赖，修改一个部分会影响到其他部分。
    * **僵化不灵活**：难以适应业务需求的变化。
    * **过度集中化**：所有数据和决策都集中在一个地方，导致效率低下。
    * **工具选择不当**：使用了与需求不匹配的工具，阻碍开发和变更管理。
  * 为避免这些问题，良好的数据架构在设计时应**考虑到可逆性**，以降低变更成本。
* 良好数据架构的基础
  * 在数据工程生命周期的基础上，以下六个方面共同构成了企业在任何数据成熟度阶段的良好数据架构基础：
    1. **安全性（Security）**
    2. **数据管理（Data Management）**
    3. **DataOps**
    4. **数据架构（Data Architecture）**
    5. **编排（Orchestration）**
    6. **软件工程（Software Engineering）**
  - 这些领域的相互作用构建了一个稳固的数据架构体系。
- 数据架构是一个持续演变的过程
  - 良好的数据架构并不是一个一劳永逸的解决方案。
  - 它是一个**不断演变的有机体**，随着环境的变化而调整。
  - 事实上，正如前述的定义，**变化和演进**是数据架构的核心意义和存在的目的。
- Principles of Good Data Architecture
  - 我们建议您仔细研究这两个框架，识别其中有价值的观点，并找出存在分歧的地方。
  - 在此基础上，我们希望通过以下**数据工程架构原则**来进一步扩展和阐述这些支柱：
    1. **明智地选择通用组件**
    2. **为失败做好规划**
    3. **为可扩展性而设计**
    4. **架构即领导力**
    5. **始终保持架构思维**
    6. **构建松耦合的系统**
    7. **做出可逆的决策**
    8. **优先考虑安全性**
    9. **拥抱 FinOps（云财务管理）**
- Major Architecture Concepts
  - Domains and Services
    - 领域（Domain）
      - **领域**指的是你正在为其设计架构的**现实世界中的主题领域**。
      - 它是业务活动或特定功能的集合，通常与企业的核心业务相关。
    - 服务（Service）
      - **服务**是一组特定的功能，其目标是**完成一项任务**。
      - 例如，你可能有一个专门处理**销售订单**的服务，其唯一职责是**在订单创建时进行处理**。
      - 这个服务不会涉及其他功能，比如库存管理或用户资料更新。
    - **领域与服务的关系**： 一个领域通常包含多个服务。
    - **跨领域的服务共享**： 有时，不同的领域可能会**共享某些服务**。
- Distributed Systems, Scalability, and Designing for Failure 
  - **分布式系统、可扩展性和故障设计**
  - **可扩展性（Scalability）**
    - **可扩展性**指的是系统在需求增加时，能够通过增加容量来提升性能和处理能力。
    - **示例场景：**
      * 当查询量大幅增加时，你可能需要横向扩展系统以处理更高的请求速率。
      * 处理海量数据集时，系统应具备水平扩展的能力。
    - **解决方案：**
      * 使用分布式数据库或分布式计算框架（如 Apache Spark、Hadoop）。
      * 采用分区和分片策略对数据进行拆分。
      * 使用负载均衡器将流量分配到多个实例。
  * **弹性（Elasticity）**
    * **弹性**是可扩展系统的一种能力，指的是系统可以根据当前的工作负载**动态地扩展或收缩**。
      * **高度弹性的系统**可以在需求增加时自动扩展，同时在需求下降时自动缩减，从而节约成本。
    * **示例场景：**
      * 电商网站在促销活动期间需要迅速扩展服务器处理大量订单请求。
      * 在云环境中，当工作负载较低时，系统自动缩减资源以节省费用。
      * **缩减至零（Scale to Zero）**：当系统空闲时，自动关闭服务以节约成本。
    - **解决方案：**
      * 使用云服务的自动扩展功能（如 AWS Auto Scaling、Azure Scale Sets）。
      * 利用 Kubernetes 等容器编排工具管理容器的动态伸缩。
  - 可用性（Availability）
    - **可用性**指的是一个 IT 服务或组件在某个时间段内**处于可操作状态的百分比**。
      - 它通常以 **99.9%（三个九）** 或 **99.99%（四个九）** 的形式表示。
    - **示例场景：**
      * 一个银行的支付系统需要 99.99% 的高可用性，以确保客户能随时完成支付。
      * 内容分发网络（CDN）需要保持高可用性以确保全球用户能够快速访问内容。
    - **解决方案：**
      * 实施冗余和故障转移机制，确保当某个节点或数据中心故障时，服务仍然可用。
      * 使用负载均衡器分散请求，避免单点故障。
      * 部署在多区域和多可用区的数据中心。
  * 可靠性（Reliability）
    * **可靠性**指的是系统在规定的时间内，按照既定的标准执行其预期功能的**概率**。
    * 可靠的系统不仅要维持高可用性，还需要在不同的情况下确保数据的正确性和一致性。
    - **示例场景：**
      * 医疗系统在患者信息存储和查询时，要求数据的高度可靠性。
      * 物流系统需要确保包裹追踪数据的准确性。
    - **解决方案：**
      * 使用分布式一致性协议（如 Raft 或 Paxos）确保数据的正确性。
      * 实现数据备份和快照，便于在数据损坏时恢复。
      * 使用监控和日志记录系统（如 Prometheus、ELK）检测异常并及时响应。
![](Data%20Engineer%20Study/%E6%88%AA%E5%B1%8F2025-03-27%20%E4%B8%8B%E5%8D%888.45.32.png)
![](Data%20Engineer%20Study/%E6%88%AA%E5%B1%8F2025-03-27%20%E4%B8%8B%E5%8D%888.46.02.png)<!-- {"width":727} -->
- **紧耦合与松耦合：层级、单体架构与微服务**
  - 在设计数据架构时，你需要决定在不同的**领域（Domains）**、**服务（Services）**和**资源（Resources）**之间应包含多少相互依赖关系。
  - 在依赖性和独立性之间，有一个完整的选择范围：
  * **紧耦合（Tight Coupling）**：
    * 系统中各个部分的依赖关系非常紧密，每个领域和服务都高度依赖其他领域和服务。
    * 如果一个部分出现故障或需要更改，可能会对整个系统产生连锁反应。
    * 这种方式虽然在某些情况下可以提供较高的性能和一致性，但缺乏灵活性。
  * **松耦合（Loose Coupling）**：
    * 系统中的领域和服务被设计为**去中心化**，它们之间的依赖关系较少或完全独立。
    * 每个团队可以独立开发和部署服务，不需要担心其他服务的变更。
    * 但需要注意的是，过度松耦合可能导致数据孤岛，使不同团队之间的数据无法共享和利用。
  * 在实际应用中，**好的数据架构**往往是在紧耦合和松耦合之间**找到合适的平衡**，以满足特定的业务需求。
* **团队协作中的耦合问题**
  * 在松耦合的环境中，各个团队可以更快速地迭代和创新，但这种独立性也带来了潜在的问题：
    * 数据格式和标准不统一，导致数据无法直接复用。
    * 缺乏明确的**数据责任制**，可能出现数据不一致的情况。
    * 数据的质量和完整性容易受到影响。
  * 因此，为了避免这些问题，需要确保：
    1. **制定统一的标准**：团队间遵循通用的数据格式和接口规范。
    2. **明确数据的所有权和责任**：每个数据域都应有清晰的责任人。
    3. **建立数据治理体系**：确保数据在不同领域之间的流通和使用是可靠且安全的。
- 架构层次（Architecture Tiers）
  - 在数据架构的设计过程中，了解架构的不同层级非常重要。典型的架构通常包含以下层级：
    1. **数据层（Data Tier）**：负责存储和管理数据，包括数据库、数据仓库、数据湖等。
    2. **应用层（Application Tier）**：处理数据的读取、写入和业务逻辑。
    3. **业务逻辑层（Business Logic Tier）**：执行具体的业务规则和数据转换。
    4. **展示层（Presentation Tier）**：向用户展示数据的界面或提供 API 服务。
  - 在设计时，确保这些层之间**适度解耦**，有助于：
    * 提高系统的可靠性和灵活性。
    * 使维护和扩展更加简单。
    * 降低因为一个层的问题导致整个系统崩溃的风险。
- 单层架构与多层架构
  1. **单层架构（Single-Tier Architecture）**
     * 所有功能（数据、业务逻辑和展示）集中在一个系统或应用中。
     * 适用于**小型应用**或**简单的原型开发**。
     * 缺点是扩展性差，难以维护。
  2. **多层架构（Multitier Architecture）**
     * 系统的不同功能被划分到不同的层中，每层专注于特定的任务。
     * 常见的多层架构包括**三层架构**：
       * 数据层
       * 应用层
       * 展示层
     * 这种架构具备良好的扩展性和维护性，适合**大型系统**和**复杂业务场景**。
  * **示例场景：**
    * 在一个电商系统中：
      * **数据层**存储商品信息、订单记录和用户数据。
      * **应用层**处理订单创建、支付和库存管理。
      * **展示层**提供用户界面和 API 接口供前端访问。
* 微服务架构（Microservices）
  * 与单体架构相比，微服务架构代表了**完全相反的设计理念**。
  - 在微服务架构中：
    * 服务是**独立的**、**去中心化的**，且高度**松耦合**。
    * 每个服务**专注于执行特定的功能**，并且与其他服务保持最小的依赖关系。
    * **单一服务的故障**不会影响其他服务的正常运行。
  * 这种设计极大地提升了系统的**灵活性**和**可扩展性**，特别适合需要快速迭代和不断变化的业务场景。
![](Data%20Engineer%20Study/%E6%88%AA%E5%B1%8F2025-03-27%20%E4%B8%8B%E5%8D%888.52.43.png)<!-- {"width":832} -->
- 微服务架构的核心特点
  1. **独立性**
     * 每个微服务都是一个独立的单元，可以独立开发、部署和扩展。
     * 即使某个服务出现故障，其他服务依然可以正常运行。
  2. **专注单一功能**
     * 每个微服务解决一个特定的业务问题，例如用户管理、订单处理或支付系统。
     * 这种设计遵循**单一职责原则**（Single Responsibility Principle）。
  3. **松耦合**
     * 服务之间通过 API 或消息队列进行通信，避免直接依赖。
     * 使用 REST、gRPC 或 Kafka 等工具来管理服务间的通信。
  4. **技术多样性**
     * 每个服务可以根据需要使用不同的编程语言、框架和数据库。
     * 不需要统一所有服务的技术栈。
  5. **弹性扩展**
     * 微服务可以根据流量负载进行**独立扩展**，而不是整体扩展整个系统。
     * 常用于应对突发流量，例如在电商促销活动期间。
* 从单体架构到微服务的转换
  * 许多企业在一开始使用单体架构是合理的，因为它简单且易于快速迭代。
    * 然而，随着业务的增长，单体架构的**维护成本**和**扩展成本**急剧上升。
  - **常见的问题包括：**
    * 难以快速迭代，发布新功能变慢。
    * 系统稳定性降低，一个模块的故障可能导致整个系统崩溃。
    * 代码库复杂且混乱，开发人员难以理解和维护。
  - 因此，将单体架构拆分为微服务成为一个自然的选择。
- 如何将单体架构拆分为微服务？
  - 转换过程取决于单体架构的复杂程度和拆分的难易度。以下是常见的拆分策略：
  1. 识别领域和边界
     * 首先识别业务中的**领域（Domain）**，明确每个领域的核心功能。
     * 使用 **领域驱动设计（DDD）** 将系统划分为多个子领域。
     * 每个子领域对应一个微服务。
     - **示例：**
       * 订单领域 → 订单服务
       * 支付领域 → 支付服务
       * 用户管理领域 → 用户服务
  2. 逐步拆分而非一次性重构
     * 不建议直接重写整个系统。
     * 采用**增量式重构**，逐步将单体架构中的功能拆分成独立的微服务。
     * 使用 **Strangler Fig Pattern（绞杀者模式）**：
       * 逐步将功能重写到新的微服务中，同时保留旧系统，直到新系统完全替代旧系统。
  3. 使用 API 和消息队列解耦
     * 服务之间通过**API 网关**或**消息队列**进行通信。
     * 采用 REST、GraphQL 或 gRPC 提供接口服务。
     * 使用 Kafka、RabbitMQ 等消息队列处理异步任务。
  4. 数据分区和拆分
     * 每个微服务应拥有自己的数据库，避免多个服务共享同一数据库。
     * 使用 **数据库分区** 或 **CQRS（Command Query Responsibility Segregation）** 模型来拆分数据。
     - **示例：**
       * 用户服务管理用户信息数据库
       * 订单服务管理订单数据库
       * 支付服务管理支付交易数据库
  5. 获得利益相关者的支持
     * 拆分单体架构不仅仅是技术问题，也是**组织问题**。
     * 在执行之前，确保与业务、开发、运维等相关利益方沟通，取得共识和支持。
     * 制定清晰的迁移计划，并逐步执行。
- ETL
![](Data%20Engineer%20Study/%E6%88%AA%E5%B1%8F2025-03-27%20%E4%B8%8B%E5%8D%888.59.00.png)<!-- {"width":776} -->
- ELT
![](Data%20Engineer%20Study/%E6%88%AA%E5%B1%8F2025-03-27%20%E4%B8%8B%E5%8D%888.59.29.png)<!-- {"width":776} -->
![](Data%20Engineer%20Study/%E6%88%AA%E5%B1%8F2025-03-27%20%E4%B8%8B%E5%8D%889.06.24.png)<!-- {"width":776} -->
![](Data%20Engineer%20Study/%E6%88%AA%E5%B1%8F2025-03-27%20%E4%B8%8B%E5%8D%889.06.41.png)<!-- {"width":618} -->
- 数据集市（Data Marts）
  - **数据集市**是数据仓库的一个**精炼子集**，专门用于支持特定部门、子组织或业务线的**分析和报告**需求。
  - 与服务于整个企业的**数据仓库**相比，数据集市通常聚焦于某个特定的业务领域。
  - 每个部门都可以拥有根据自身需求定制的数据集市。
- 数据集市存在的原因
  - 数据集市的存在主要有两个核心原因：
  1. **数据的易获取性**
     * 数据集市让分析师和报表开发人员能够**更方便、更快速**地访问所需的数据。
     * 不需要在庞大的数据仓库中搜索和提取数据，节省了时间和精力。
  2. **性能优化**
     * 数据集市提供了一个额外的**数据转换阶段**，通常是在初步的 ETL（Extract, Transform, Load）或 ELT（Extract, Load, Transform）之后进行。
     * 特别是当分析报告涉及复杂的**数据表关联**和**聚合运算**时，数据集市显著提升查询性能。
     * 数据转换过程可以预先进行表的**关联（Join）和聚合（Aggregation）**，使实时查询的执行速度更快。
* 数据集市的工作流
  * 数据集市的典型工作流如下：
  1. **数据摄取**
     * 从各种源系统提取原始数据，并加载到数据仓库中。
  2. **数据清洗和转换**
     * 通过 ETL 或 ELT 管道对数据进行清洗、转换和标准化。
  3. **数据仓库存储**
     * 将转换后的数据存储在企业级数据仓库中。
  4. **数据集市生成**
     * 通过进一步的数据转换，将数据仓库中的数据聚合、汇总，并存储到针对特定业务领域的数据集市中。
  5. **分析与报告**
     * 分析师和报告开发人员直接从数据集市中获取数据进行查询、分析和生成报告。
* 示例：数据集市的实际应用
  - 假设你在一家大型零售公司工作，公司拥有一个包含所有销售、库存和客户数据的中央数据仓库。
    * **销售部门**可能需要一个专门的销售数据集市，用于分析销售额、客户行为和地区销售表现。
    * **库存管理团队**可能需要一个库存数据集市，跟踪库存水平、补货周期和仓储效率。
    * **财务部门**则可能需要一个财务数据集市，汇总销售收入、成本和利润率数据。
  - 每个数据集市仅包含与对应部门相关的数据，简化了数据访问并加快了分析速度。
![](Data%20Engineer%20Study/%E6%88%AA%E5%B1%8F2025-03-27%20%E4%B8%8B%E5%8D%889.08.13.png)<!-- {"width":776} -->
![](Data%20Engineer%20Study/%E6%88%AA%E5%B1%8F2025-03-27%20%E4%B8%8B%E5%8D%889.02.02.png)<!-- {"width":782} -->
- **数据湖（Data Lake）**
  - 数据湖曾被寄予厚望，被认为是一种**数据民主化**的力量，能够让企业自由地从**无尽的数据源**中获取信息。
  - 然而，第一代数据湖（**Data Lake 1.0**）虽然做出了一些贡献，但整体上并未兑现它的承诺。
    - 数据湖 1.0 的起点是基于 **HDFS（Hadoop Distributed File System）** 的存储架构。
    * 随着云计算的普及，数据湖逐渐转移到**云对象存储**中，如 Amazon S3、Azure Blob Storage 等。
    * 云存储的优势在于**存储成本极低**且**容量几乎无限**，这为数据湖的概念提供了强大的支持。
  * 不同于传统数据仓库中存储和计算的紧密耦合，数据湖采用了**存储与计算分离**的方式：
    * **存储层**：可以存储**任何规模、任何类型**的数据。
    * **计算层**：当需要查询或转换数据时，可以随时启用按需集群，借助**MapReduce**、**Spark**、**Presto**、**Hive** 等工具进行处理。
- 数据湖 1.0 的教训
  1. **数据湖不是数据治理的替代品**
     * 数据湖需要强大的**数据治理机制**，包括数据目录、元数据管理、数据质量监控等。
  2. **合规性需求不可忽视**
     * 数据湖必须具备灵活的数据管理功能，以应对数据删除和更新的合规性要求。
  3. **数据管理比存储更重要**
     * 数据湖不仅仅是一个存储空间，它需要具备**数据管理能力**，确保数据可发现、可理解、可用。
  4. **成本控制是关键**
     * 在追求数据湖的同时，企业需要评估维护和管理的成本，避免因管理复杂性导致成本失控。
* 融合、下一代数据湖和数据平台
  * 针对**第一代数据湖**的局限性，许多企业和技术公司都在努力改进数据湖的概念，以更好地兑现它的承诺。
    * 例如，**Databricks** 提出了 **数据湖仓（Data Lakehouse）** 的概念。
  * 数据湖仓融合了数据仓库的**控制、数据管理和数据结构**，同时保留了数据湖的**对象存储**特性，并支持多种查询和数据转换引擎。
  - 与传统数据湖不同，数据湖仓具备以下特性：
    * **ACID 事务支持**：支持原子性、一致性、隔离性和持久性（ACID），确保数据的可靠性和一致性。
    * **数据管理能力**：允许数据更新、删除和版本控制，而不仅仅是简单的数据存储。
  - **数据湖仓**的出现标志着**数据湖与数据仓库的融合**。
- 云数据仓库架构的演变
  - 与此同时，**云数据仓库**的技术架构也在不断进化，逐渐向数据湖的方向靠拢。
  - 现代云数据仓库具备以下特点：
    1. **存储与计算分离**：计算资源和存储资源独立扩展，降低成本并提升灵活性。
    2. **支持 PB 级查询**：具备处理超大规模数据的能力。
    3. **支持多类型数据**：不仅存储结构化数据，还可处理非结构化和半结构化数据（如 JSON、Parquet 等）。
    4. **与大数据技术集成**：可以直接与 **Spark**、**Beam** 等大数据处理引擎集成。
  - 这些特性使云数据仓库逐步具备了类似数据湖的功能。
- 数据湖与数据仓库的进一步融合
  - 我们相信，数据湖与数据仓库之间的**融合趋势**将会持续。
    * 在概念上，数据湖和数据仓库仍然是两种不同的架构。
    * 但在实际应用中，它们的功能会越来越接近，最终使得普通用户在日常使用中**感知不到二者的界限**。
    * 数据分析师、数据工程师和业务用户将能够在一个统一的环境中，无缝地访问、查询和分析数据，而无需关心数据存储的底层架构。
* 数据平台的崛起
  * 目前，多家云服务提供商已经推出了集成了数据湖和数据仓库功能的**数据平台**。
  * 这些平台提供一整套紧密集成的工具，支持从结构化数据到非结构化数据的处理。
![](Data%20Engineer%20Study/%E6%88%AA%E5%B1%8F2025-03-27%20%E4%B8%8B%E5%8D%889.20.01.png)<!-- {"width":807} -->
- 未来，数据工程师在选择数据架构时，将不再需要在数据湖和数据仓库之间做出二选一的决定。
  - 相反，他们将根据以下因素选择最合适的**融合数据平台**：
    * **供应商生态系统**：企业已有的云环境或技术堆栈。
    * **技术集成能力**：数据平台与现有数据工具和服务的兼容性。
    * **开放性**：是否支持跨平台的数据流通和数据共享。
* Modern Data Stack
  - **现代数据栈**是当前数据分析架构中非常流行的一种形式，它代表了一种更加灵活、模块化的抽象方式，并预计在未来几年会得到广泛应用。
  - 相比于过去依赖昂贵的**单体化工具集**的传统数据栈，现代数据栈的核心目标是：
    * **使用基于云的组件**
    * **即插即用（Plug-and-Play）**
    * **简单易用**
    * **经济高效**
  - 通过这些方式，现代数据栈构建了一个模块化、成本效益高的数据架构。
- **现代数据栈的主要组件**
  1. **数据管道（Data Pipelines）**
     * 用于从各种数据源提取数据，并将其加载到存储系统。
     * 常用工具：Fivetran、Airbyte、Stitch 等。
  2. **数据存储（Storage）**
     * 通常为云存储或数据湖，例如 Amazon S3、Google Cloud Storage。
     * 数据仓库也常用，如 Snowflake、BigQuery、Redshift。
  3. **数据转换（Transformation）**
     * 使用 SQL 或其他工具进行数据清洗、转换和建模。
     * 常用工具：dbt（Data Build Tool）。
  4. **数据管理与治理（Data Management/Governance）**
     * 确保数据质量、数据合规性和数据安全性。
     * 常用工具：Monte Carlo、Collibra、Alation。
  5. **数据监控（Monitoring）**
     * 监测数据管道运行状态、数据延迟和错误。
     * 常用工具：Datadog、Prometheus。
  6. **数据可视化（Visualization）**
     * 将数据转换为直观的图表和仪表板，供业务人员查看和分析。
     * 常用工具：Tableau、Looker、Power BI。
  7. **数据探索（Exploration）**
     * 支持数据分析师和业务人员直接查询和探索数据。
     * 常用工具：Hex、Mode、DataGrip。
- **现代数据栈的特点和优势**
  1. **自助服务化**
     * 现代数据栈支持**自助式分析**和**自助式数据管道管理**，即使是非技术人员也可以轻松使用数据。
  2. **敏捷的数据管理**
     * 通过模块化的架构，数据团队可以快速响应业务需求，进行数据建模和分析。
  3. **开源与透明性**
     * 许多现代数据栈工具是开源的，用户可以查看代码、提出功能建议，甚至直接提交代码改进。
     * 用户社区非常活跃，推动了工具的快速迭代和优化。
  4. **清晰的定价**
     * 相比传统工具复杂的授权和收费模式，现代数据栈的工具通常提供**透明的定价结构**，按使用量计费，更加经济实惠。
  5. **即插即用的模块化架构**
     * 现代数据栈由多个独立模块组成，可以根据需求自由组合和替换，形成灵活的解决方案。
- **Lambda 架构**
  - 在 **2010 年代早期到中期**，随着 **Kafka** 等高度可扩展的消息队列和 **Apache Storm**、**Samza** 等流处理框架的出现，处理**流数据**的需求迅速增长。
  - 这些技术使企业能够对海量数据进行**实时分析**，包括：
    * **用户行为聚合**
    * **实时排序**
    * **产品推荐**
  - 然而，随着企业同时需要处理 **批处理数据** 和 **流数据**，数据工程师面临了如何**整合这两种数据处理方式**的挑战。
    - 为了解决这一问题，**Lambda 架构**成为了早期的一种广受欢迎的解决方案。
- Lambda 架构的核心概念
  - Lambda 架构由三个独立的层次组成，每个层次都有特定的功能：
  1. **批处理层（Batch Layer）**
     * 负责处理**大规模的历史数据**。
     * 使用数据仓库或分布式计算引擎（如 Apache Spark、Hadoop）进行数据转换和聚合。
     * 生成预计算的视图，用于复杂分析和历史数据查询。
  2. **速度层（Speed Layer）**
     * 也称为**流处理层**，处理**实时数据**，提供低延迟的结果。
     * 使用流处理框架（如 Apache Storm、Flink）在几秒或几毫秒内提供分析结果。
     * 数据通常存储在 NoSQL 数据库中，用于快速查询。
  3. **服务层（Serving Layer）**
     * 提供一个统一的接口，整合**批处理结果**和**流处理结果**。
     * 用户通过服务层执行查询，系统会根据需求选择最新的流数据或已计算的批处理数据。
- Lambda 架构的工作原理
  1. **数据源**
     * 数据源通常是不可变的，采用 **Append-Only**（仅追加）的方式存储数据，例如 Kafka 或 Pulsar。
  2. **数据分流**
     * 数据被同时发送到批处理层和速度层。
     * **速度层**负责实时处理，提供快速但可能不完全准确的结果。
     * **批处理层**则处理大规模数据，提供最终一致的结果。
  3. **数据合并**
     * **服务层**根据需要，将流数据和批处理数据的查询结果进行整合，提供最终的视图给用户。
* Lambda 架构的优势
  * **实时性与准确性兼得**：
    * 同时处理流数据和批数据，确保用户能够快速获取实时结果，同时也能获取经过精确计算的批处理结果。
  * **高容错性**：
    * 由于批处理层存储了完整的数据集，即便速度层出现问题，数据依然可以通过批处理层恢复。
  * **适用于复杂场景**：
    * 在需要进行实时分析和历史数据查询的场景下，Lambda 架构非常有用。
* Lambda 架构的挑战和缺点
  - 尽管 Lambda 架构在早期解决了很多问题，但它也有明显的缺点：
  1. **代码冗余**
     * **同一套业务逻辑需要在批处理层和速度层分别实现**，导致代码重复和维护成本高。
  2. **数据一致性问题**
     * 流处理和批处理的结果可能存在差异，导致数据一致性问题。
  3. **运维复杂性**
     * 需要同时管理多个系统（如 Spark、Storm、NoSQL 等），增加了运维的复杂性。
  4. **性能开销**
     * 数据需要被同时写入批处理层和速度层，增加了系统的存储和计算成本。
- 替代方案：Kappa 架构
  - 由于 Lambda 架构的上述缺点，后来的技术发展催生了 **Kappa 架构** 作为替代方案。
  - **Kappa 架构的核心理念：**
    * **所有数据处理都采用流处理的方式进行**。
    * **无须区分批处理和流处理**，而是使用一个统一的流处理引擎来执行所有任务。
    * 使用像 **Apache Flink** 或 **Apache Kafka Streams** 这样的流处理框架，可以实现实时和历史数据的统一处理。
![](Data%20Engineer%20Study/%E6%88%AA%E5%B1%8F2025-03-29%20%E4%B8%8B%E5%8D%884.43.40.png)<!-- {"width":739} -->
![](Data%20Engineer%20Study/%E6%88%AA%E5%B1%8F2025-03-29%20%E4%B8%8B%E5%8D%884.44.01.png)<!-- {"width":864} -->
- Kappa 架构
  - **Kappa 架构**是由 **Jay Kreps** 在 2014 年提出的，作为对 **Lambda 架构**缺点的回应。
  - Kappa 架构的核心思想是：
    - **为什么不只使用一个流处理平台作为所有数据处理的基础，包括数据摄取、存储和服务？**
  - 这种架构基于 **事件驱动** 的方式进行数据管理和处理，实现真正的 **事件流架构**。
- 在 Kappa 架构中：
  * **实时处理** 和 **批处理** 不再分开。
  * 无论是实时数据还是历史数据，都通过**同一个事件流**进行读取和处理。
  * 批量处理不再依赖独立的批量存储，而是通过**重放历史事件流**来完成。
* Kappa 架构的工作原理
  * 在 Kappa 架构中，所有数据以事件流的形式存储在一个持久化的**事件日志**中（通常是 Kafka 等分布式消息系统）。
  * 它包括以下关键组件：
  1. **事件流（Event Stream）**
     * 数据源产生的事件以流的形式不断写入事件存储。
     * 事件是不可变的，并且支持重复读取和回放。
  2. **流处理引擎（Stream Processing Engine）**
     * 使用如 **Apache Flink**、**Kafka Streams** 等工具对事件数据进行实时处理。
     * 如果需要重新计算历史数据，处理引擎可以**重放**事件流。
  3. **数据存储**
     * 实时处理的结果会存储在 NoSQL 数据库或数据湖中，以便后续查询和分析。
  4. **查询和分析**
     * 用户可以通过 API 或 SQL 查询实时获取最新的处理结果。
- 为什么选择 Kappa 架构？
  - Kappa 架构的提出主要是为了解决 Lambda 架构的以下问题：
  1. **代码冗余问题**
     * 在 Lambda 架构中，相同的逻辑需要在**速度层**和**批处理层**中分别实现两次。
     * 而在 Kappa 架构中，所有处理都通过一个流处理引擎完成，只需要维护一套代码。
  2. **数据一致性问题**
     * Lambda 架构中，批处理和流处理的结果可能存在差异，导致数据不一致。
     * Kappa 架构避免了这个问题，因为所有处理都是基于相同的事件流。
  3. **更简单的架构**
     * Kappa 架构去掉了批处理层，降低了系统的复杂性。
  4. **灵活的事件重放**
     * 如果需要重新处理数据，例如修复错误或重新训练模型，只需从事件存储中重放历史数
* Kappa 架构的局限性
  - 尽管 Kappa 架构有诸多优点，但它在实际应用中并没有被广泛采用，主要有以下原因：
  1. **流处理的复杂性**
     * 尽管流处理概念简单，但实际执行起来非常复杂。
     * 事件顺序、去重、延迟处理等都是需要解决的挑战。
  2. **成本高昂**
     * 流处理系统需要保持事件存储的完整性，以支持数据的重放和回溯。
     * 这意味着需要存储大量的事件数据，存储和计算成本较高。
  3. **不适合所有场景**
     * 对于需要处理大量历史数据的场景，批处理仍然比流处理更加**高效和经济**。
     * 数据仓库和数据湖提供的批量处理能力，通常在处理 PB 级别的历史数据时更加划算。
* 实际应用场景
  * **适合 Kappa 架构的场景：**
    * **金融交易监控**：需要对交易进行实时监控，检测异常行为。
    * **物联网数据分析**：实时分析传感器数据，检测设备故障。
    * **实时推荐系统**：根据用户的行为数据，立即生成个性化推荐。
  - **不适合 Kappa 架构的场景：**
    * **大规模历史数据处理**：如定期执行的数据分析任务或数据仓库查询。
    * **数据治理和合规性场景**：需要对大量数据进行清洗、转换和审计时。
![](Data%20Engineer%20Study/%E6%88%AA%E5%B1%8F2025-03-29%20%E4%B8%8B%E5%8D%884.49.59.png)<!-- {"width":767} -->
- **数据流模型与统一的批处理和流处理**
  - 在 **2010 年代**，随着 **Hadoop** 生态系统的兴起，工程师们开始探索如何解决批处理和流处理的分离问题。
  - **Lambda 架构** 和 **Kappa 架构** 都试图通过组合不同的工具解决这一问题。
    - 然而，由于这些工具往往不是为此目的设计的，结果通常是复杂且难以维护的系统。
  - 尽管如此，这两种架构提供了宝贵的经验和灵感，推动了后续的数据处理模型的发展。
- 核心挑战：统一批处理和流处理
  - **批处理和流处理的统一**一直是数据工程中的一大挑战。
    * **批处理（Batch Processing）**：通常用于处理**历史数据**，在固定的时间间隔内运行。
      * 适合执行大规模的聚合和复杂计算。
    * **流处理（Stream Processing）**：用于处理**实时数据**，提供低延迟的处理能力，通常用于实时监控和事件响应。
  - 挑战：多代码路径问题
    * 在传统架构中，批处理和流处理使用不同的工具和技术栈。
    * 这意味着开发人员需要维护两套代码，一套用于批处理任务，一套用于流处理任务。
    * 代码冗余和逻辑不一致性成为常见的问题。
* Dataflow 模型的出现
  * 为了解决这些问题，**Google** 开发了 **Dataflow 模型**，并通过 **Apache Beam** 实现了这一模型。
  * **Dataflow 模型的核心理念：**
    * **将所有数据视为事件流，并通过不同的窗口进行聚合。**
  - 在 Dataflow 模型中：
    * **流数据** 被视为 **无界数据流（Unbounded Data）**，它没有固定的结束时间。
    * **批数据** 被视为 **有界数据流（Bounded Data）**，它有明确的开始和结束边界。
    * **窗口（Windowing）**：无论是流数据还是批数据，都可以通过窗口进行划分和聚合。
- 窗口的类型
  - 在 Dataflow 模型中，窗口是处理数据的关键方式。
  - 常见的窗口类型包括：
  1. **固定窗口（Fixed Window）**
     * 数据按照固定的时间间隔进行划分。
     * 适用于定期报告和周期性分析。
  2. **滑动窗口（Sliding Window）**
     * 窗口会以一定的步长滑动，每次都会生成一个新的窗口。
     * 适用于需要频繁更新的实时数据分析。
  3. **会话窗口（Session Window）**
     * 根据事件之间的**间隔时间**动态创建窗口。
     * 适用于分析用户行为数据，例如检测用户的活跃时长。
* Dataflow 的优势
  1. **批处理与流处理的统一**
     * **Dataflow 视批处理为流处理的特例**。
     * 使用同一套代码处理实时数据和历史数据。
  2. **简化代码维护**
     * 开发人员只需要维护一套代码，避免了传统 Lambda 架构中多代码路径的问题。
  3. **灵活的数据处理方式**
     * 支持动态窗口调整和延迟数据处理，确保数据处理的准确性。
  4. **生态系统支持**
     * 除了 Apache Beam 之外，许多现代数据处理框架（如 **Apache Flink** 和 **Apache Spark**）也采用了类似的模型。
* 示例：Dataflow 模型的实际应用
  - 假设你需要分析一个电商平台上的订单数据：
    * 实时监控订单量，发现异常情况。
    * 每小时生成销售报告。
  - 使用 Dataflow 模型，你可以：
    1. 将所有订单视为事件流。
    2. 使用**滑动窗口**进行实时监控，检测是否有异常订单量。
    3. 使用**固定窗口**执行批量聚合，生成每小时的销售报告。
![](Data%20Engineer%20Study/%E6%88%AA%E5%B1%8F2025-03-29%20%E4%B8%8B%E5%8D%885.12.51.png)<!-- {"width":807} -->
- **谁参与数据架构的设计？**
  - 数据架构的设计并不是孤立完成的，它涉及多个角色和利益相关者的协作。
    - 在大型企业中，虽然通常会聘请**数据架构师（Data Architect）来专职负责架构设计，但这些架构师需要紧密了解最新的技术趋势**和数据生态的发展。
  - **传统的“象牙塔式”数据架构时代已成为过去。**
    - 过去，架构设计往往是与工程实践脱节的，但如今，随着数据工程和软件工程的快速发展，这种划分正在逐渐消失。
  - 现代数据架构设计强调：
    * **敏捷性**：架构设计和工程实践紧密结合。
    * **协作性**：数据架构师和数据工程师协作，共同推动项目实施。
    * **业务驱动**：与业务团队紧密合作，确保架构设计符合业务需求。
* 数据架构师与数据工程师的角色
  * **数据架构师**
    * 专注于宏观层面的架构设计。
    * 确定数据存储、数据流、数据治理和安全性策略。
    * 选择合适的技术和工具，确保系统的可扩展性和稳定性。
  * **数据工程师**
    * 负责具体的技术实现，包括数据管道的开发、数据清洗和数据转换。
    * 确保数据架构的设计在实际应用中能够高效运行。
    * 参与系统优化和性能调优。
  - **在小型公司或数据成熟度较低的企业中**，通常没有专职的数据架构师。
    - 在这种情况下，**数据工程师**可能会兼任数据架构师的角色，负责数据的全生命周期管理。
- 与业务利益相关者的协作
  - 在设计数据架构时，除了技术团队，还需要与**业务利益相关者**密切合作。
  - **常见的业务利益相关者包括：**
    1. **产品经理**
       * 确定数据需求，了解业务目标。
    2. **数据分析师和数据科学家**
       * 负责数据分析和建模，对数据的质量和结构有直接需求。
    3. **运营团队**
       * 需要实时监控数据，及时了解业务表现。
    4. **法务和合规团队**
       * 确保数据架构符合相关的法律和数据隐私保护法规（如 GDPR）。
  - 数据架构师和数据工程师需要与这些利益相关者沟通，评估不同架构方案的**权衡和取舍**。
- 数据架构设计中的关键权衡
  - 在设计数据架构时，通常会面临一系列的选择和权衡，例如：
  1. **数据仓库 vs. 数据湖**
     * **数据仓库**：适合结构化数据和复杂查询分析。
     * **数据湖**：支持存储结构化和非结构化数据，更适合大规模数据存储和机器学习场景。
     * **权衡点**：性能 vs. 存储成本、数据治理 vs. 灵活性。
  2. **云平台的选择**
     * AWS、Azure、Google Cloud 等云平台提供了不同的服务和定价策略。
     * **权衡点**：成本 vs. 功能、供应商锁定风险 vs. 多云策略。
  3. **批处理 vs. 流处理**
     * **批处理**：适合定期数据分析和报表生成。
     * **流处理**：适用于实时监控和异常检测场景。
     * **权衡点**：实时性 vs. 计算成本、准确性 vs. 时效性。
  4. **统一的批流处理框架**
     * 使用像 **Apache Beam** 或 **Apache Flink** 这样的框架，可以在同一代码路径中同时处理批数据和流数据。
     * **权衡点**：开发效率 vs. 系统复杂性。
* 总结
  * 数据架构的设计是一个**协作过程**，涉及数据架构师、数据工程师和业务利益相关者。
  * 在缺乏专职数据架构师的小型企业中，数据工程师往往需要承担双重角色。
  * 设计过程中需要深入理解不同架构方案的**优缺点**，并根据业务需求做出权衡。
  * 投资时间深入学习数据架构的设计原则，有助于在实际项目中做出更加合理的技术决策。
---
## CHAPTER 4: Choosing Technologies Across the Data Engineering Lifecycle
- 防止技术选择的常见陷阱
  - 在实践中，许多团队容易陷入以下几种技术选择的陷阱：
    1. **追逐新技术（Shiny Object Syndrome）**
       * 团队盲目追求最新的技术趋势，而忽视了技术的实际业务价值。
    2. **简历驱动开发（Resume-Driven Development）**
       * 工程师为了提升简历吸引力，选择使用流行技术，而不是基于实际需求做决策。
    3. **缺乏架构规划**
       * 在没有清晰架构蓝图的情况下，直接开始技术选型，导致系统复杂度迅速增加。
  - **应对策略：**
    * 始终围绕业务目标选择技术。
    * 在选择前先完成架构设计。
    * 使用小规模 POC（Proof of Concept）进行技术验证。
- 架构优先，技术其次
  - 在数据工程中，成功的关键在于**先定义架构，再选择技术**。
    1. **明确架构目标**：根据业务需求设计一个合理的架构蓝图。
    2. **评估技术方案**：基于架构需求，评估不同技术的优劣。
    3. **平衡权衡点**：在成本、性能、团队能力和业务价值之间找到最佳平衡。
    4. **持续迭代**：技术不是一成不变的，根据业务需求和市场变化不断优化技术栈。
  - 通过这种方法，数据工程师不仅能够选择出真正适合企业的技术方案，还能确保系统长期稳定运行，推动业务增长。
- 团队规模与能力
  - 在进行数据工程技术选型时，**了解团队的规模和技术能力**是第一步。
- 团队规模的影响
  * **小型团队**：通常由 **1-5 人**组成，团队成员需要**身兼多职**，负责从数据摄取、清洗到建模、分析的各个阶段。
    * **推荐策略**：使用更多的**托管服务（Managed Services）和SaaS 工具**来简化基础设施管理。
    * **专注于业务价值**：将有限的精力集中在真正能为业务带来价值的问题上。
  * **中型团队**：通常有 **5-20 人**，可能会出现一些基础的角色分工，例如数据工程师、数据分析师、数据科学家等。
    * **推荐策略**：采用一定的**自建解决方案**，同时结合云服务以降低运维成本。
  * **大型团队**：超过 **20 人**，通常拥有明确的职能划分，有专职的数据架构师、数据工程师、数据分析团队等。
    * **推荐策略**：构建自定义的数据平台，采用复杂的技术栈和分布式系统，以满足大规模数据处理需求。
* **避免“伪工程崇拜”（Cargo-Cult Engineering）**
  * 在数据工程领域，有时小团队会尝试模仿像 Google、Netflix 等科技巨头的复杂技术架构。
  - **伪工程崇拜（Cargo-Cult Engineering）** 指的是：
    - **盲目模仿大型科技公司的先进技术，而忽视自身的实际需求和能力。**
  - **问题的表现包括：**
    * 使用不适合团队规模的复杂工具或系统。
    * 将大量时间和资源投入到学习和维护这些工具上，却无法带来实际的业务价值。
    * 由于缺乏经验，系统可靠性和性能反而下降。
  - **应对策略：**
    * **聚焦业务场景**：选择能够**直接解决业务问题**的工具，而不是追求技术的“潮流”。
    * **使用托管服务**：对于小团队，推荐使用 **AWS Glue**、**Google Dataflow** 等托管服务，减少运维负担。
      * **AWS Glue** 是 **Amazon Web Services (AWS)** 提供的 **无服务器数据集成服务**，主要用于 **ETL（Extract、Transform、Load）** 工作。
        * 将清洗和转换后的数据加载到 **Amazon Redshift** 进行进一步分析。
          * **Amazon Redshift** 是由 **AWS（Amazon Web Services）** 提供的**云数据仓库**服务，专门用于执行大规模的**数据分析和查询**。
          * 它支持**结构化数据**和**半结构化数据**的存储和分析，能够处理**PB（Petabyte）级别**的数据。
          * Redshift 特别适合需要进行复杂 SQL 查询和数据分析的场景。
        * **每天一次的报表生成** → **选择 AWS Glue**
      * **Google Dataflow** 是 **Google Cloud** 提供的 **流式和批量数据处理服务**，基于 **Apache Beam** 构建。
        * **实时监控和异常检测** → **选择 Google Dataflow**
    * **简化架构**：避免不必要的复杂性，优先采用易于管理和扩展的技术。
* **上市速度（Speed to Market）**
  * 在科技领域，**上市速度决定胜负**。
    - 这意味着你需要选择能够帮助团队**更快交付功能和数据**的技术，同时保持**高质量标准**和**安全性**。
    - 更快的产品上线，意味着可以更早地从用户那里获得反馈，快速学习并迭代改进。
  - 不要追求完美
    - **完美是好的敌人。**
    - 有些数据团队在技术选型上**犹豫不决**，为了找到“完美”的解决方案，可能会花费**数月甚至数年**的时间进行讨论和调研。
    - 然而，长时间的决策拖延和缓慢的产品交付最终会导致团队失去竞争力。
  - 在现实中：
    * **行动缓慢**的数据团队往往无法提供预期的业务价值。
    * 我们曾见过一些数据团队，因为交付速度过慢而最终解散。
    * **快速交付**能够赢得更多的市场机会，同时积累宝贵的用户反馈。
* 早期交付，持续迭代
  * **持续交付价值，尽早交付价值。**
    * **优先交付业务价值**：
      * 不要过度纠结技术的细节，使用现有的工具和团队熟悉的技术，尽快将产品推向市场。
    * **快速反馈**：
      * 通过用户反馈了解实际需求，及时进行调整和优化。
    * **持续迭代**：
      * 根据市场反馈不断改进产品，而不是试图在首次发布时就做到完美。
  - **例子：**
    * 如果你的团队熟悉 **AWS Glue** 或 **Google Dataflow**，即使它们并不是市场上最新的工具，也可以快速完成 ETL 数据管道的搭建。
    * 如果你需要分析销售数据，直接使用团队熟悉的 **Redshift** 或 **BigQuery** 来完成，而不是花时间研究和试验一个全新的数据仓库。
- 避免不必要的复杂性
  - **不要进行无谓的“繁重工作”。**
  - 有时候，团队会选择复杂的技术方案，试图解决一些实际上不太重要的问题。这种过度复杂化的问题在数据工程中非常常见。
  - 常见的错误示例：
    * **过度设计数据架构**：在不必要的情况下引入复杂的微服务架构，而简单的单体架构就能解决问题。
    * **过早优化**：在数据量不大的时候过度优化查询性能，导致时间和资源的浪费。
    * **追求最新技术**：为了使用最新的流处理技术而替换掉团队熟悉且稳定的批处理系统。
  - **解决方法：**
    * 选择技术时，**以业务价值为导向**，判断它是否真正能够加快交付速度。
    * 使用团队熟悉的工具和技术，减少学习成本和试错时间。
    * 拒绝不必要的复杂性，优先使用简单且可靠的解决方案。
- 选择帮助你快速前进的工具
  - **好的工具**应该满足以下条件：
    1. **快速交付**
       * 工具应该能够帮助团队快速搭建数据管道、执行数据转换和提供分析结果。
    2. **可靠性**
       * 工具需要具备较高的稳定性，减少故障发生率，从而降低修复时间。
    3. **安全性**
       * 数据安全是首要考虑因素，选择具备合规性和数据保护能力的工具。
    4. **易于集成**
       * 工具应该能够轻松地与现有的数据源、数据仓库和 BI 工具集成。
    5. **降低维护成本**
       * 使用托管服务或 SaaS 工具，减少基础设施管理的负担。
  - **示例：**
    * **AWS Glue**：适合需要快速构建 ETL 管道的小型团队。
    * **Redshift**：适合需要快速查询和分析大量数据的业务场景。
    * **Fivetran**：适合需要快速从多个 SaaS 数据源拉取数据的企业。
    * **dbt**：适合需要在数据仓库中快速进行数据转换和建模的团队。
- ### 总结
  * **速度决定胜负**：在数据工程中，快速交付比追求完美更重要。
  * **避免拖延决策**：不要花费过多时间纠结于技术选择，选用熟悉且成熟的工具。
  * **持续交付价值**：尽早发布产品，从用户那里获得反馈，快速迭代改进。
  * **避免复杂性**：不要陷入不必要的技术复杂性，应优先考虑简单、高效的解决方案。
  * **选择合适的工具**：选择能帮助你快速、可靠、安全地交付数据产品的技术。
- **互操作性（Interoperability）**
  - **互操作性**指的是不同技术或系统之间**连接、交换信息和交互的能力**。
    - 在数据工程中，你很少只使用一种技术或系统。
    - 相反，你需要确保它们能够无缝协作，形成一个完整的数据管道和分析体系。
- 为什么互操作性重要？
  - 在数据工程中，通常涉及以下多个环节：
    1. **数据采集**：从 CRM、ERP、API、日志等提取数据。
    2. **数据存储**：存入数据湖（如 Amazon S3）或数据仓库（如 Redshift、BigQuery）。
    3. **数据处理**：使用工具如 Apache Spark、AWS Glue、Google Dataflow 进行数据清洗和转换。
    4. **数据分析和可视化**：使用 Tableau、Power BI、Looker 等进行数据展示。
    5. **数据共享和应用**：将数据提供给下游的机器学习模型或业务应用。
  - 在这些环节中，每个系统和工具都需要**顺畅地连接**和**数据交互**。
  - 良好的互操作性可以带来以下好处：
    * **降低集成成本**：减少手动配置和开发工作量。
    * **加快数据流转**：确保数据在不同系统之间快速传输和转换。
    * **提高灵活性**：方便在未来替换或升级系统。
- 互操作性的衡量标准
  - 在评估两个技术之间的互操作性时，你可以从以下几个方面进行考量：
  1. **集成的难易程度**
     * 技术 A 和技术 B 之间的集成是**无缝的**还是需要**大量手动配置**？
     * 是否提供了**现成的集成插件**或**API 支持**？
  2. **标准化的支持**
     * 是否支持标准化的协议，例如：
     * **JDBC** 或 **ODBC**：用于数据库连接。
     * **REST API**：用于数据交换。
     * **gRPC**：用于高效的微服务通信。
     * 数据格式是否标准化（如 JSON、Parquet、Avro）？
  3. **生态系统的兼容性**
     * 该技术是否与主流的云服务（如 AWS、Azure、GCP）兼容？
     * 是否与现有的数据仓库、BI 工具和机器学习平台顺畅连接？
  4. **数据流向的灵活性**
     * 数据是否能够在不同系统之间**双向流动**？
     * 是否支持实时数据流和批量数据导入？
  5. **可扩展性和维护性**
     * 如果未来更换某个技术，是否需要重写大量代码？
     * 是否有模块化的架构，方便替换或扩展？
* 如何提升互操作性？
  - 在实际工作中，你可以采取以下策略来提升系统的互操作性：
  1. **选择标准化的技术**
     * 使用支持 JDBC、ODBC、REST API 等标准协议的工具。
  2. **优先使用有现成集成的产品**
     * 选择像 AWS Glue、Google Dataflow 这类提供丰富集成的产品，减少开发工作量。
  3. **保持数据格式的兼容性**
     * 使用常见的数据格式如 **JSON**、**Parquet**、**Avro**，确保不同系统之间的数据转换更简单。
  4. **设计模块化架构**
     * 采用**松耦合**的架构，将数据处理、存储和分析模块分开，便于替换和升级。
  5. **监控和日志管理**
     * 使用统一的监控工具（如 AWS CloudWatch）来跟踪数据在不同系统间的流转情况，及时发现问题。
* **成本优化与业务价值**
  * 在理想情况下，你可能会希望自由地尝试所有最新、最酷的技术，而不需要考虑成本、时间投入或业务价值。
  * 但在现实中：
    * **预算** 和 **时间** 是有限的。
    * **成本** 是选择合适数据架构和技术时的关键约束。
    * 企业期望数据项目能产生**正向的投资回报（ROI）**。
  * 因此，作为数据工程师，你需要理解和控制项目中产生的各种成本。
  * 成本的三种视角
    - 在数据工程中，我们通常从以下**三种视角**来看待成本：
    1. **总拥有成本（TCO）**
    2. **机会成本**
    3. **FinOps（云成本管理）**
- ### 1. 总拥有成本（Total Cost of Ownership，TCO）
  - **总拥有成本（TCO）** 指的是一个项目从启动到结束所需的所有**直接成本**和**间接成本**的总和。
  - 直接成本
    - 这些是**与项目直接相关的开支**，包括：
      * 工程师、数据分析师的薪资。
      * 使用云服务的账单（如 AWS、GCP、Azure）。
      * 数据存储和计算资源的消耗。
  * 间接成本
    - 这些是**无论项目是否存在都必须支付的成本**，例如：
      * 企业基础设施维护。
      * 数据中心管理。
      * 法律和合规管理。
* ### 2. 资本支出 vs. 运营支出
  - 在分析 TCO 时，成本还可以分为两种类型：
    1. **资本支出（CapEx）**
       - **一次性大额支出**，用于购买硬件、软件或数据中心设备。
       * 在传统 IT 环境中，公司通常需要预先购买服务器和存储设备。
       * 硬件和软件的成本会随着时间逐渐折旧。
       * CapEx 投资的回报通常是**长期的**。
    2. **运营支出（OpEx）**
       - **持续的、按需支付的费用**，通常是基于使用量的定价模式。
       * 使用云服务时，大部分成本属于 OpEx，例如存储、计算和网络流量费用。
       * OpEx 提供了更大的灵活性，使团队可以根据需求调整资源。
  - **建议：**
    * **小型企业和初创公司** → 推荐使用 **OpEx**，借助云服务快速启动项目，减少前期投资。
    * **大型企业** → 如果数据量巨大且长期稳定，可以考虑部分 **CapEx** 投资，优化长期成本。
* ### 3. 机会成本
  * **机会成本** 指的是**在选择某项技术时，放弃的其他可能选择所带来的收益**。
  * **如何降低机会成本？**
    * 使用**托管服务**或**SaaS**工具减少基础设施管理工作。
    * 尽早交付**最小可行产品（MVP）**，快速验证业务价值。
    * 根据业务需求灵活调整技术栈，避免过度工程化。
* ### 4. FinOps：云成本管理
  - **FinOps**（Financial Operations）是一种针对云成本管理的方法。
  - 在云环境下：
    * **成本波动大**：按使用量付费，容易出现成本失控。
    * **资源动态变化**：需要不断监控和优化。
  * FinOps 的核心原则
    1. **透明度**：提供实时的成本数据和分析报告。
    2. **协作**：财务、工程和业务团队共同决策，优化成本。
    3. **优化**：通过自动化和监控工具发现资源浪费并进行优化。
  - **常用的 FinOps 工具：**
    * **AWS Cost Explorer**：查看 AWS 资源的成本和使用情况。
    * **Azure Cost Management**：管理 Azure 云的成本。
    * **Google Cloud Billing**：提供详细的费用分析和预测。
- **总机会成本（Total Opportunity Cost of Ownership，TOCO）**
  - **总机会成本（TOCO）** 是指在选择某项技术、架构或流程时，由于放弃其他选择而产生的潜在损失。
  - 在数据工程中，每当你选择一种数据技术栈时，你不仅承担了它的直接成本，还承担了放弃其他可能选择所导致的**机会成本**。
  - TOCO 的核心概念
    1. **排他性**
       * 选择了技术栈 A，就意味着你放弃了技术栈 B、C 和 D 的机会。
       * 每个选择都伴随着对其他可能选择的放弃，而这些被放弃的机会可能会带来更大的价值。
    2. **长期绑定**
       * 即使是在云环境中，没有直接购买硬件或长期许可证，你依然会对选定的技术进行深度依赖。
       * 当技术栈成为你数据流程的核心部分后，迁移成本将大幅增加。
    3. **技术过时风险**
       * 数据领域的发展非常迅速，一项热门的技术可能在几年内被淘汰。
       * 如果你的数据栈无法适应新技术或扩展需求，迁移到新技术的成本会极其高昂。
    4. **迁移能力**
       * 一个优秀的技术选型应当考虑未来的**迁移成本**和**灵活性**。
       * 如果你需要更换技术，能否快速、低成本地完成迁移？
  * 如何降低 TOCO？
    1. **选择具备灵活性的技术**
       * 使用支持标准接口（如 JDBC、ODBC、REST API）的技术，方便未来切换。
       * 优先选择具备跨平台能力的云服务，如 AWS Glue、Google Dataflow 等。
    2. **采用模块化架构**
       * 设计时尽量将数据管道拆分为独立模块，降低不同模块之间的耦合度。
       * 使用像 **Apache Airflow** 或 **dbt** 这样的工具，可以在不同环境下灵活切换。
    3. **避免供应商锁定**
       * 尽量使用开源技术或者支持多云的解决方案，例如 **Apache Spark**、**Trino** 等。
       * 在供应商选择时，评估未来退出或迁移的成本。
    4. **定期评估技术栈**
       * 定期检查当前技术是否仍符合业务需求。
       * 关注新兴技术，确保自己在市场变化时具备转移的能力。
    5. **构建迁移计划**
       * 在引入新技术时，提前考虑未来的迁移路径。
       * 制定清晰的数据备份和数据导出策略，确保迁移时的数据完整性。
* 什么是 FinOps？
  * **FinOps**（**Financial Operations**）是一种专注于**云成本管理**和**业务价值优化**的方法论。
  - 它的核心目标是：
    * **提升企业的财务透明度**
    * **确保云支出带来最大化的业务价值**
    * **动态调整资源使用以控制成本**
  - 尽管 FinOps 涉及到**成本节约**，但它的真正重点不是单纯地减少开支，而是通过合理的云支出**推动业务增长**。
- 为什么 FinOps 很重要？
  - 在云环境中，大部分支出都属于**运营支出（OpEx）**，公司按需支付计算、存储和网络资源的费用。
  - 与传统的**资本支出（CapEx）**相比，云支出的灵活性更高，但如果没有合理的管理，可能会导致以下问题：
    * **成本失控**：资源闲置或过度使用，导致高昂的云账单。
    * **缺乏透明度**：业务团队和财务部门无法清晰了解哪些服务在消耗资金。
    * **低效决策**：没有及时优化资源，导致资源浪费。
  - **FinOps 通过实时监控和调整，让企业能够快速应对变化，同时确保云支出产生实际的业务价值。**
- FinOps 的核心理念
  - FinOps 的核心理念类似于 **DevOps**，强调在跨职能团队中实现协作。主要包括以下三点：
  1. **财务透明化**
     * 提供实时的云成本数据，让工程、业务和财务团队共同理解成本结构。
  2. **责任归属**
     * 明确每个团队在云成本中的责任，确保每个业务部门都了解其资源消耗情况。
  3. **持续优化**
     * 通过监控和数据分析，动态调整云资源配置，以优化成本和性能。
* FinOps 的实施步骤
  - 实施 FinOps 通常分为以下三个阶段：
    1. **告知阶段（Inform）**
       * 提供可视化的云支出报告和实时监控。
       * 识别成本高的服务和未充分利用的资源。
    2. **优化阶段（Optimize）**
       * 使用策略如自动缩放、Spot 实例和储蓄计划来降低成本。
       * 根据实际需求选择合适的云服务和存储类型。
    3. **运营阶段（Operate）**
       * 持续监控云支出和资源使用。
       * 通过 KPI（关键绩效指标）评估 FinOps 的有效性。
* FinOps 不是节省成本，而是创造价值
  * FinOps 并不只是为了**节省开支**，更重要的是通过**合理的云支出**创造业务价值。
  * 如何衡量 FinOps 的业务价值？
    1. **收入增长**：通过快速迭代和产品发布加速市场占有率。
    2. **客户增长**：通过弹性扩展支持更多用户，同时维持良好的用户体验。
    3. **成本节约**：通过精细化成本管理减少不必要的支出。
    4. **业务敏捷性**：快速响应市场变化，确保业务决策的灵活性。
![](Data%20Engineer%20Study/%E6%88%AA%E5%B1%8F2025-03-29%20%E4%B8%8B%E5%8D%886.43.24.png)<!-- {"width":698} -->
- **今天与未来：不可变技术 vs. 临时性技术**
  - 在像数据工程这样快速发展的领域中，人们往往容易**聚焦于未来**，期待技术的进步和创新。
    - 然而，这种对未来的过度关注可能会导致**过度架构设计**和**过度工程化**，忽视了当前的实际需求。
  - 即使你现在选择了一项看似面向未来的技术，当未来真正到来时，这项技术可能已经过时。
    - **未来往往和我们想象的不同**。
  - 活在当下，兼顾未来
    - **正如许多人生导师所说的：“活在当下。”**
  - 在数据工程中，最明智的做法是：
    1. 选择适合**当前和近期需求**的技术。
    2. 保持架构的**灵活性**，以便未来进行调整和扩展。
    3. 了解哪些技术是相对稳定的，哪些技术是短暂流行的。
  - 在做技术决策时，可以问自己：
    * **我们现在的技术状况如何？**
    * **未来的业务目标是什么？**
    * **哪些技术可能长期存在？哪些技术可能很快消失？**
  - 了解这些问题的答案，将有助于你在技术架构中做出合理的选择。
- **1. 不可变技术（Immutable Technologies）**
  - **不可变技术**指的是那些**经受时间考验**，并且预计在未来仍将存在的技术。
  - 这些技术通常是：
    * **基础性技术**：如云存储、网络、计算基础设施等。
    * **编程语言和标准**：如 SQL、Bash、C 等，几十年来一直被广泛使用。
    * **基础架构和协议**：如 TCP/IP、HTTP 等。
  * **为什么选择不可变技术？**
    * 它们具备**长期稳定性**。
    * 技术生态成熟，拥有丰富的社区和文档支持。
    * 你对它们的投资在未来依然有价值。
- **2. 临时性技术（Transitory Technologies）**
  - **临时性技术**是指那些**生命周期较短**、容易被替代或淘汰的技术。
  - 这些技术通常经历以下阶段：
    * **初期炒作**：某项新技术被广泛宣传，迅速吸引关注。
    * **快速增长**：许多企业开始采用，技术生态逐步成熟。
    * **逐渐衰落**：随着替代技术出现，市场份额逐渐减少。
  * **为什么需要注意临时性技术？**
    * 投资在这些技术上的时间和资源可能会浪费。
    * 依赖某项临时性技术可能导致**迁移成本过高**。
    * 技术人才流失后，维护和升级的难度增加。
  * **Apache Hive 的衰落**
* **如何平衡不可变技术和临时性技术？**
  - 在构建数据工程架构时，你需要平衡两者的使用：
    1. **基础设施层面**
       * 使用不可变技术作为基础，例如 Amazon S3、SQL 数据库等。
       * 选择稳定的编程语言，如 Python、SQL。
    2. **业务逻辑层面**
       * 在需要快速创新的场景中，可以尝试临时性技术。
       * 比如使用新的 AI 工具进行实验性项目，但不要过度依赖。
    3. **架构设计层面**
       * 采用**模块化和松耦合的架构**，方便技术的替换和升级。
       * 使用标准化接口（如 REST API 或 JDBC）来降低技术依赖。
    4. **定期评估**
       * 每年定期评估技术栈的表现，及时淘汰不再合适的临时性技术。
       * 保持对市场动态的敏感度，跟踪哪些技术正在兴起或衰落。
- ### Our Advice
  - 在数据工程领域，由于**工具和最佳实践变化迅速**，我们建议**每两年评估一次技术栈**，以确保你的数据架构仍然符合业务需求。
  - 技术评估的周期性
    * **每两年评估**：技术的生命周期通常很短，新工具和方法会迅速涌现。
    * **定期复盘**：通过定期评估，及时了解哪些工具仍然适用，哪些需要替换。
    * **避免技术债务**：定期更新技术栈，防止长期依赖过时的工具。
  * 不可变技术作为基础
    * 在数据工程生命周期中，尽量找到**不可变技术（Immutable Technologies）并将它们作为你的基础架构**。
  - **不可变技术的特点：**
    * 经受住了时间的考验。
    * 具备广泛的行业应用。
    * 拥有丰富的生态系统和社区支持。
    * 提供长期稳定性。
  * **围绕不可变技术选择临时性技术**
    * 尽管临时性技术（Transitory Technologies）变化迅速，它们在特定场景下仍然非常有用。
    * **策略：**
      1. **模块化架构**：将临时性技术封装在模块中，以便未来替换。
      2. **接口标准化**：使用 API、SQL、JDBC 等标准接口，降低迁移成本。
      3. **实验性应用**：在创新或试验阶段使用临时性技术，而非核心业务中。
  - **考虑技术的迁移成本**
    - 在选择新技术时，不仅要考虑它的优势，还要**提前评估迁移的难度和成本**。
    - 关键问题：
    1. **退出的难度**：
       * 如果这项技术不再适用，你是否能够快速迁移到其他工具？
    2. **数据格式和存储**：
       * 数据是否以开放格式存储（如 Parquet、Avro）？这将有助于在不同平台之间迁移。
    3. **依赖性**：
       * 是否有高度的供应商锁定？
    4. **生态系统支持**：
       * 如果公司停止维护该技术，是否有替代方案或社区支持？
  * 避免“熊陷阱”（Bear Traps）
    * **熊陷阱**比喻一种难以逃脱的技术困境。
    * 一旦你深度依赖某个工具，可能会面临巨大的迁移成本和风险。
    * 许多公司由于早期选择不当，在系统老化后不得不投入巨资进行系统重构。
  * 解决方法：
    * **开放标准优先**：选择支持开放数据格式的工具，例如 Parquet、Avro、JSON。
    * **云中立性**：避免过度依赖单一云提供商，考虑多云或混合云架构。
    * **数据分层存储**：在对象存储层保留原始数据，确保即使上层工具变化，数据仍然安全。
* 总结：如何做出明智的技术决策
  1. **建立不可变的核心**：
     * 选择长期稳定的存储、基础架构和编程语言作为你的数据基础。
  2. **灵活使用临时性技术**：
     * 在数据管道的外围使用新兴技术，保持实验性，同时为替换做好准备。
  3. **定期技术评估**：
     * 每两年审查一次当前的技术栈，衡量技术的适用性和未来潜力。
  4. **降低迁移成本**：
     * 采用模块化架构，确保技术组件可以随时更换。
     * 使用标准化接口和开放数据格式，以减少技术锁定的风险。
  5. **保持敏锐的市场洞察力**：
     * 关注数据工程领域的技术趋势，同时避免盲目追逐热点。
* ### 位置：选择在哪里运行技术栈
  - 在现代企业中，**技术栈的部署位置**已成为企业战略中的重要决策之一。
    - 随着**云计算**的快速普及，越来越多的公司将工作负载迁移到云平台，如 **AWS**、**Azure** 和 **Google Cloud Platform (GCP)**。
  - 但是，企业需要在以下四种主要环境中进行选择：
    1. **本地部署（On-Premises）**
    2. **云端（Cloud）**
    3. **混合云（Hybrid Cloud）**
    4. **多云（Multicloud）**
  - 每种环境都有其独特的优势和挑战。企业在做出决定时需要权衡**成本**、**性能**、**安全性**和**业务需求**。
- 1. 本地部署（On-Premises）
  - **本地部署**指的是在企业自有的数据中心或服务器上运行技术栈。
  - 特点：
    * 数据和基础设施由企业完全控制。
    * 适用于需要高度安全性或合规性的场景。
    * 一次性资本支出（CapEx）较高。
    * 运维成本和管理复杂度较高。
  - 适用场景：
    * **金融机构**：例如银行和保险公司，因数据隐私和监管要求，倾向于本地部署。
    * **制造业**：需要在工厂内运行物联网（IoT）设备并进行实时数据处理。
    * **延迟敏感型应用**：如实时交易平台，无法容忍网络延迟。
  - **示例：**
    - 一家银行为了确保客户数据安全，将核心支付系统运行在本地数据中心，同时采用冗余服务器和灾备系统。
- **2. 云端（Cloud）**
  - **云部署**指的是将数据和应用程序托管在公有云服务提供商（如 AWS、Azure 或 GCP）上。
  - 特点：
    * 按需付费，支持弹性扩展。
    * 快速部署和上线，减少基础设施管理。
    * 全球化覆盖，便于跨区域部署。
    * 提供大量托管服务，降低运维负担。
  * 适用场景：
    * **初创公司和中小企业**：无需投入大量初期资本，可以快速启动业务。
    * **数据分析和机器学习**：利用云上的强大计算资源进行数据分析和模型训练。
    * **季节性业务**：例如电商促销期间的资源需求激增，云服务可灵活扩展。
  * **示例：**
    - 一家零售公司在 AWS 上运行其推荐系统，通过使用 AWS Glue 处理数据，使用 Redshift 进行分析，并在高峰期自动扩展。
- **3. 混合云（Hybrid Cloud）**
  - **混合云**指的是将一部分工作负载保留在本地数据中心，同时将另一部分迁移到云端。
- **4. 多云（Multicloud）**
  - **多云部署**指的是同时使用两个或多个云服务提供商的服务。
  - 特点：
    * 避免供应商锁定，提供更多选择和谈判能力。
    * 提高业务连续性，即使一个云平台故障，另一个平台仍可运行。
    * 最佳化成本，通过不同云服务的价格差异进行优化。
    * 使用各个云平台的独特功能。
  * 适用场景：
    * **全球化企业**：需要在多个地区提供服务，通过选择区域内最优的云提供商降低延迟。
    * **高可靠性需求**：使用多云架构进行冗余备份，确保业务连续性。
    * **成本优化**：在数据存储、计算和网络资源之间灵活选择最低成本的云服务。
![](Data%20Engineer%20Study/%E6%88%AA%E5%B1%8F2025-03-29%20%E4%B8%8B%E5%8D%887.14.18.png)<!-- {"width":591} -->
---
## CHAPTER 5: Data Generation in Source Systems
### Sources of Data: How Is Data Created?
- 在了解生成数据的系统中不同的**操作模式**时，首先要明白数据是如何产生的。
  - **数据**本质上是一组**未经组织、缺乏上下文**的事实和数字。
  - 它的产生方式多种多样，可以分为**模拟数据**和**数字数据**。
- ### 1. 模拟数据（Analog Data）
  - **模拟数据**是指在**现实世界中**产生的物理信息。
  - **示例：**
    * **语言和声音**：人们的语音对话、演讲。
    * **手势和肢体语言**：如手语、挥手示意。
    * **书写和记录**：在纸张上书写的文字或绘制的图像。
    * **音乐和声音**：乐器演奏、自然界的声音。
  - **特点：**
    * 通常是**短暂的**，一旦消失很难再现。
    * 缺乏直接的数字化形式，需要通过**数字化设备**进行转换。
  - **示例场景：**
    * 一场面对面的讨论，除非进行录音或记录，否则对话内容很快会被遗忘。
    * 一幅画在纸上的图画，只有拍照或扫描后才能成为数字数据。
- ### 2. 数字数据（Digital Data）
  - **数字数据**是以**数字形式**表示的信息，它可以通过以下两种方式产生：
  - 2.1 模拟数据转换为数字数据
    - 通过设备将模拟数据转换为数字数据是最常见的方式之一。
    - **示例：**
      * **语音转文字**：语音助手（如 Siri、Alexa）将人的语音转换为文本数据。
      * **扫描和拍摄**：手机扫描文档或拍照生成数字图像。
      * **传感器数据**：物联网设备（IoT）记录温度、湿度、运动等物理信息并生成数字数据。
    - **场景示例：**
      * 在客户服务中心，客户与人工客服的通话会被录音，并通过**语音转文字**技术转换为文本数据，方便后续分析。
  * 2.2 原生数字数据
    * 有些数据是由数字系统直接创建的，无需转换。
    - **示例：**
      * **电商交易数据**：用户下单后，系统记录订单信息、支付状态和物流信息。
      * **社交媒体互动数据**：点赞、评论、分享等行为都会直接生成数字数据。
      * **金融交易数据**：股票买卖、信用卡消费等金融交易会实时生成交易记录。
      * **日志数据**：应用程序和服务器自动记录的日志信息。
    - **场景示例：**
      * 当用户在电商平台完成支付后，系统会生成一条交易记录，包含用户 ID、商品 ID、订单金额等信息，并存储在数据库中。
![](Data%20Engineer%20Study/%E6%88%AA%E5%B1%8F2025-03-30%20%E4%B8%8B%E5%8D%881.12.49.png)<!-- {"width":669} -->
- 了解数据源的关键性
  - 当你负责数据工程项目时，了解你的**数据源系统**是非常重要的。
  - 为什么需要了解数据源？
    1. **数据质量管理**：了解数据源的特点有助于识别和处理数据中的异常值和错误。
    2. **数据建模**：准确理解数据的上下文，确保数据模型的合理性。
    3. **数据传输和存储**：了解数据量、生成频率和格式，选择合适的存储和传输方案。
    4. **性能优化**：了解数据源的工作原理，有助于优化数据提取和处理流程。
- 如何了解你的数据源？
  1. **阅读数据源的文档**
     * 详细了解数据源的结构、字段定义、数据格式和数据更新频率。
     * 理解 API 或数据库接口的使用方法。
  2. **与数据源团队合作**
     * 与负责数据源的开发人员或产品团队沟通，了解数据生成的背景和业务逻辑。
  3. **分析数据样本**
     * 获取一部分数据样本进行分析，观察数据的分布、字段类型和潜在的异常值。
  4. **监控数据流**
     * 使用数据监控工具（如 Prometheus、Grafana）了解数据流量和系统性能。
### **数据源系统：核心概念**
- **数据源系统**是指产生数据的系统，它们通过各种方式生成和存储数据。
  - 在数据工程的日常工作中，你会频繁地与这些数据源打交道。了解它们的基本概念和特性，有助于更高效地提取和管理数据。
- 主要的数据源包括：
  1. **文件和非结构化数据**
     - 什么是文件？
       - **文件**是指存储在磁盘上的一组**字节序列**，通常由应用程序写入和读取。
     - 它们用于保存：
       * **本地参数**：如应用程序的配置文件。
       * **事件和日志**：记录系统行为和用户活动。
       * **多媒体数据**：如图片、音频和视频文件。
       * **数据交换**：在不同系统之间传输数据的常用方式。
     * 即使在现代数据管道中，数据工程师也常常需要处理通过文件传递的数据。
     - 例如：
       * 政府机构、企业或合作伙伴可能通过 **Excel** 或 **CSV 文件**发送数据。
       * 数据源系统的输出结果也可能以**文本文件**的形式存储。
  2. **API（应用程序编程接口）**
     - **API**（Application Programming Interface）是一种标准化的接口，用于在**不同系统之间交换数据**。
     - 在数据工程中，API 常用于：
       * **数据获取**：从外部服务或内部系统中提取数据。
       * **数据传输**：将清洗或转换后的数据发送到目标系统。
       * **实时数据流**：处理和分析流式数据。
     * API 的优势
       * **实时性**：API 提供了实时数据访问的能力。
       * **灵活性**：支持多种数据格式（如 JSON、XML）。
       * **自动化**：可以集成到数据管道中，实现数据的自动拉取和处理。
     * **API 的挑战**
       * 尽管 API 提供了标准化的数据交换方式，但在实际使用中可能遇到以下挑战：
       1. **数据复杂性**
          * 一些 API 提供的数据结构复杂，数据工程师需要编写额外的代码进行解析和转换。
       2. **性能问题**
          * API 请求频繁时可能导致接口超时或数据丢失。
       3. **速率限制（Rate Limiting）**
          * 许多 API 设有调用次数限制，超过限额可能导致请求被拒绝。
       4. **数据不一致**
          * 数据可能在不同时间点返回不一致的结果，需要数据工程师处理这些异常。
     * API 数据的实际应用场景
       * **电商平台**：通过支付网关 API 获取实时支付状态。
       * **社交媒体分析**：从 Twitter API 获取用户的推文和互动数据。
       * **金融服务**：从第三方金融数据提供商的 API 获取实时股票行情。
       * **物流公司**：通过物流 API 查询包裹的运输状态。
![](Data%20Engineer%20Study/%E6%88%AA%E5%B1%8F2025-03-30%20%E4%B8%8B%E5%8D%881.16.56.png)<!-- {"width":739} -->
- 数据工程师的建议
  - 在处理数据源系统时，数据工程师需要：
  1. **了解数据源系统的特性**
     * 阅读数据源的文档，了解数据的结构、字段和更新频率。
     * 理解 API 的速率限制和错误处理机制。
  2. **选择合适的工具和方法**
     * 使用 **Pandas**、**Spark** 等工具解析 CSV、JSON 等文件数据。
     * 使用 **requests**、**httpx** 等库调用 API。
  3. **数据验证和清洗**
     * 确保数据完整性，处理缺失值和异常数据。
  4. **监控和维护**
     * 实施数据管道的监控，检测 API 请求失败或数据延迟。
### **应用程序数据库（OLTP 系统）**
- **应用程序数据库**是用于存储应用程序状态的数据库。
  - 一个典型的例子是**银行账户的数据库**：
    * 当客户进行交易或付款时，应用程序会更新银行账户的余额。
    * 这些更新数据的操作会被写入数据库，实时反映账户的最新状态。
- 在大多数情况下，应用程序数据库是一个 **OLTP（Online Transaction Processing）系统**，即**在线事务处理系统**。
- 什么是 OLTP 系统？
  - **OLTP 系统**专注于**高频率的读写操作**，通常用于处理大量的事务，例如：
    * 用户下单
    * 银行转账
    * 商品库存更新
    * 社交媒体点赞或评论
  - OLTP 的特点：
    1. **低延迟**
       * 通常在**毫秒级**完成数据的读写操作（不包括网络延迟）。
    2. **高并发**
       * 支持成千上万的用户同时访问和更新数据。
    3. **事务驱动**
       * 数据库通过事务确保数据一致性，保障数据的准确性和完整性。
    4. **数据量较小**
       * 单次查询或更新通常涉及少量记录，而不是大规模的数据扫描。
- OLTP 数据库的常见类型
  1. **关系型数据库（RDBMS）**
     * 例如：MySQL、PostgreSQL、Oracle、SQL Server。
     * 支持强一致性和 ACID 事务，确保数据完整性。
  2. **文档数据库**
     * 例如：MongoDB、Couchbase。
     * 提供灵活的数据结构，常用于处理非结构化或半结构化数据。
  3. **图数据库**
     * 例如：Neo4j、Amazon Neptune。
     * 适用于复杂的关系型数据场景，如社交网络分析或推荐系统。
* ACID 特性
  - 在 OLTP 系统中，**ACID** 是保证数据可靠性和一致性的关键特性。
  - **ACID** 是以下四个特性的首字母缩写：
    1. **Atomicity（原子性）**
       * 一个事务中的所有操作要么全部成功，要么全部失败。
       * **示例**：银行转账，若转出失败，则转入也不会执行。
    2. **Consistency（一致性）**
       * 数据在事务执行前后必须处于**一致的状态**。
       * **示例**：从一个账户扣除的钱必须准确地存入另一个账户。
    3. **Isolation（隔离性）**
       * 并发事务不会互相影响，模拟串行执行的效果。
       * **示例**：两位用户同时购买同一商品时，系统通过隔离性防止库存被错误更新。
    4. **Durability（持久性）**
       * 一旦事务提交成功，数据会被永久保存，即使发生系统故障也不会丢失。
       * **示例**：银行交易完成后，数据不会因断电或崩溃而丢失。
* 不依赖 ACID 的场景
  * 尽管 ACID 对于数据一致性非常重要，但在某些场景下，**放宽 ACID 要求**可以显著提升性能。
    * 一些分布式数据库采用了**弱一致性模型**（如**最终一致性**）来提升吞吐量和响应速度。
  - 最终一致性（Eventual Consistency）
    * 数据更新后，所有副本不会立即同步，而是经过一段时间后达到一致。
    * 适用于对一致性要求不高的场景，例如社交媒体的点赞数更新。
  - **示例：**
    * 用户在电商平台下单后，库存数据可能不会立刻同步到所有仓库系统。
    * 但在几秒或几分钟内，系统会逐步更新所有副本。
  - **适用场景：**
    * 全球分布式系统：如 CDN 缓存、聊天应用中的已读消息状态。
    * 高并发业务场景：如新闻网站的阅读量统计。
![](Data%20Engineer%20Study/%E6%88%AA%E5%B1%8F2025-03-30%20%E4%B8%8B%E5%8D%881.29.41.png)<!-- {"width":727} -->
- 原子性事务（Atomic Transactions）
  - **原子性事务**是指一组多个数据更改操作被视为**一个整体**，要么**全部成功**，要么**全部失败**，不会出现部分成功、部分失败的情况。
  - 在 **RDBMS**（关系型数据库管理系统）中，原子性事务是 **ACID** 特性的基础之一，特别适用于需要确保数据一致性的场景。
  - 原子性事务的示例
    - **场景：银行转账**
    - 假设一款银行应用程序正在执行以下转账操作：
      * **账户 A**（来源账户）转账至 **账户 B**（目标账户）。
      * 需要确保**账户 A 的余额减少**和**账户 B 的余额增加**是一个完整的事务。
    - **过程：**
      1.查询账户 A 和账户 B 的余额。
      2.检查账户 A 的余额是否充足。
      3.从账户 A 扣除相应金额。
      4.将相同金额存入账户 B。
      5.提交事务。
    - **原子性要求：**
      * 如果**任意一步失败**（如余额不足或系统异常），事务将**回滚**，账户 A 和账户 B 的余额将保持原样。
      * 只有当**所有操作都成功**时，事务才会被提交。
* OLTP 和分析的关系
  - **OLTP（在线事务处理）系统专注于快速的数据写入和读取**，通常用于执行小型、频繁的事务，例如：
    * 银行转账
    * 电商订单创建
    * 社交媒体点赞
  - 然而，一些企业会尝试直接在 OLTP 系统上运行分析任务，例如：
    * 用户行为分析
    * 销售数据汇总
    * 实时数据监控
  - 为什么直接在 OLTP 系统上运行分析存在问题？
    1. **性能瓶颈**
       * OLTP 数据库结构设计以事务为核心，通常采用行存储。
       * 分析任务涉及大量的表扫描和复杂的聚合操作，容易导致**查询速度变慢**。
    2. **资源争抢**
       * 分析查询和事务性操作会在同一数据库中竞争资源。
       * 大型查询可能会拖慢正常的交易处理。
    3. **数据模型限制**
       * OLTP 数据库往往以**规范化模型**存储数据，有助于减少冗余，但不适合数据分析。
       * 分析型数据库通常采用**列存储**，在执行聚合和筛选操作时更加高效。
* 数据工程师的解决方案
  - 数据工程师需要理解 OLTP 的工作原理，并通过适当的架构设计，将事务性操作和分析任务解耦。
  - 常见解决方案
    1. **数据复制**
       * 使用 **ETL**（Extract, Transform, Load）或 **ELT** 管道，将 OLTP 数据复制到专用的分析数据库或数据仓库（如 Amazon Redshift、Snowflake）。
       * 确保分析查询不会影响生产数据库的性能。
    2. **数据流处理**
       * 使用数据流技术（如 Apache Kafka、Amazon Kinesis）实时捕捉数据变更事件，并写入分析系统。
    3. **读写分离**
       * 使用主从架构或读写分离策略，将写操作发送到主数据库，将分析查询发送到从数据库。
    4. **数据应用程序（Data Application）**
       * 随着 SaaS 应用程序对实时分析的需求增加，出现了将**事务处理**和**分析能力**结合的混合系统。
       * 例如 **Snowflake Unistore** 和 **SingleStore** 提供了类似的混合功能。
* 数据应用程序的案例
  * **数据应用程序（Data Application）指的是那些融合了事务处理和分析功能**的应用。
  - 场景 1：电商平台的实时分析
    * 用户下单后，订单数据立刻存入 OLTP 系统。
    * 同时，通过数据流或 CDC（Change Data Capture）技术，将数据同步到数据仓库。
    * 数据团队可以在几秒钟内分析销售趋势，监控库存变化。
  - 场景 2：金融交易风控
    * 金融机构在执行实时交易时，需要检测异常交易行为。
    * 数据应用程序将交易数据写入 OLTP 数据库，同时触发风控模型进行实时分析。
    * 如果检测到可疑行为，立即冻结账户或报警。
  - 场景 3：社交媒体的推荐系统
    * 用户点赞、评论、分享的行为存入 OLTP 数据库。
    * 分析系统通过实时数据流获取这些行为，更新推荐算法，提供个性化推荐。
### **在线分析处理系统 (OLAP)**
- 与 **OLTP 系统**（在线事务处理系统）不同，**OLAP 系统**（Online Analytical Processing System）专门用于**运行大规模的分析查询**。
  - 它擅长执行复杂的**数据聚合、过滤和多维分析**，但在处理**单条记录的查找**时通常效率较低。
- OLAP 的特点
  1. 批量数据处理
     * OLAP 系统通过**扫描大量数据**进行查询，而不是依赖索引来快速查找单条记录。
     * **列式存储**：许多 OLAP 系统使用列式存储格式（如 Parquet 或 ORC），便于执行聚合和筛选。
  2. 高吞吐量，低并发
     * 通常用于执行耗时较长的分析查询，而不是支持大量的并发写入操作。
     * 每次查询可能会涉及**数百 MB 到 GB 级别**的数据扫描。
  3. 适合交互式分析
     * 支持用户通过 BI 工具或 SQL 查询进行**实时数据探索**和**可视化分析**。
     * 常见场景包括销售数据分析、市场趋势预测等。
  4. 数据延迟
     * OLAP 系统中的数据通常来自 OLTP 系统，并经过 ETL 或 ELT 处理后加载。
     * 数据可能存在一定的延迟，通常是**T+1**（一天一更新）或**小时级**。
![](Data%20Engineer%20Study/%E6%88%AA%E5%B1%8F2025-03-30%20%E4%B8%8B%E5%8D%881.39.08.png)<!-- {"width":832} -->
- 为什么在数据源章节讨论 OLAP 系统？
  - 虽然 OLAP 系统主要用于分析查询，但在实际应用中，数据工程师经常需要从 OLAP 系统中读取数据。
  - 以下是一些典型的场景：
    1. **机器学习模型训练**
       * 数据工程师从数据仓库或数据湖中提取历史数据，供数据科学家训练机器学习模型。
       * 例如，从 Snowflake 获取过去 5 年的销售数据，用于预测未来销售趋势。
    2. **反向 ETL（Reverse ETL）**
       * 分析后的数据会被写回到原始系统中，以支持业务决策。
       * 例如，数据团队在 BigQuery 中分析客户数据后，将客户细分标签同步回 CRM 系统，以便销售团队开展精准营销。
    3. **数据共享与可视化**
       * BI 工具（如 Tableau、Looker）直接连接到 OLAP 系统，展示实时或近实时的分析结果。
       * 例如，市场团队使用 Redshift 中的销售数据，实时监控促销活动的效果。
* OLAP 系统的性能优化
  * 尽管 OLAP 系统擅长处理大规模数据分析，但不合理的使用方式可能导致性能问题。
  - 以下是一些优化策略：
    1. **分区和分桶**
       * 根据时间、地区等字段创建数据分区，以减少不必要的数据扫描。
    2. **列式存储**
       * 使用 Parquet、ORC 等列式存储格式，加快聚合查询速度。
    3. **物化视图**
       * 创建物化视图提前计算常用的聚合结果，降低查询的计算负担。
    4. **缓存层**
       * 使用 Redis、Memcached 等缓存工具，缓存常用查询结果，减少查询延迟。
![](Data%20Engineer%20Study/%E6%88%AA%E5%B1%8F2025-03-30%20%E4%B8%8B%E5%8D%881.42.44.png)<!-- {"width":656} -->
### **变更数据捕获（Change Data Capture, CDC）**
- **变更数据捕获（CDC）是一种用于从数据库中提取数据变更事件**的方法。
  - CDC 主要捕获以下三种类型的数据库变更：
    * **插入（Insert）**
    * **更新（Update）**
    * **删除（Delete）**
  - 通过 CDC，数据工程师可以**实时或近实时**地获取这些变更事件，用于：
    * **数据库之间的数据同步**
    * **数据湖或数据仓库的更新**
    * **实时流式数据处理**
* CDC 的用途
  - CDC 在现代数据架构中扮演着重要角色。以下是常见的 CDC 使用场景：
    1. **数据库复制和同步**
       * 通过 CDC 将一个数据库的变更数据复制到另一个数据库，实现**异地备份**或**灾备恢复**。
       * **示例**：从 MySQL 数据库实时同步数据到 PostgreSQL 数据库。
    2. **实时数据流处理**
       * CDC 可将数据变更事件发送至消息队列或流处理平台（如 **Kafka**、**Amazon Kinesis**），进行实时分析和监控。
       * **示例**：在电商平台中，实时监控用户下单行为并生成推荐商品。
    3. **数据仓库或数据湖更新**
       * 将 CDC 数据流发送至数据仓库（如 **Snowflake**、**BigQuery**）或数据湖（如 **Amazon S3**），确保分析数据始终保持最新状态。
       * **示例**：在销售数据更新后，数据仓库中的销售报表数据也随之更新。
    4. **事件驱动架构**
       * 通过 CDC 触发下游应用程序的事件，实现自动化工作流。
       * **示例**：在银行系统中，检测到账户异常变动后自动触发风控审核。
* CDC 的实现方式
  * 不同类型的数据库会采用不同的方式来实现 CDC。
  1. 基于数据库日志的 CDC
     * **适用场景**：主要用于关系型数据库（如 MySQL、PostgreSQL、Oracle）。
     * **实现方式**：通过读取数据库的 **事务日志**（Transaction Log）来捕捉数据变更。
     * **优势**：
       * 低延迟，几乎实时捕捉变更。
       * 对数据库性能影响较小。
     * **示例**：
       * MySQL 使用 **binlog** 进行 CDC。
       * PostgreSQL 使用 **WAL（Write-Ahead Log）**。
     - **示例：MySQL binlog 的 CDC 过程**
       1. 用户在 MySQL 中执行一条 INSERT 语句。
       2. MySQL 将变更记录写入 **binlog 文件**。
       3. CDC 工具（如 **Debezium** 或 **Maxwell**）读取 binlog 并解析出数据变更事件。
       4. 数据变更事件被传送到 Kafka 或其他消息队列。
  2. 基于触发器的 CDC
     * **适用场景**：在不支持事务日志读取的数据库中使用。
     * **实现方式**：通过在数据库中创建**触发器（Trigger）**来捕获数据变更事件，并将事件写入专用的变更表中。
     * **优势**：
       * 实现简单，易于配置。
     * **劣势**：
       * 对数据库性能影响较大。
     * **示例**：
       * 在 SQL Server 中使用触发器将变更数据存储到日志表中。
  3. 基于 NoSQL 数据库的 CDC
     * **适用场景**：云原生的 NoSQL 数据库（如 MongoDB、DynamoDB）通常提供内置的 CDC 功能。
     * **实现方式**：通过数据库的事件流功能，将数据变更事件推送到下游存储或流处理系统。
     * **优势**：
       * 原生支持，易于集成。
       * 实时性强。
     * **示例**：
       * **MongoDB Change Streams**：监听集合中的变更事件并推送到消费者。
       * **Amazon DynamoDB Streams**：将数据变更事件发送到 AWS Lambda 或 Kinesis。
* CDC 的挑战
  - 尽管 CDC 提供了许多优势，但在实际使用中也会遇到一些挑战：
    1. **数据一致性**
       * 确保在高并发场景下，数据变更事件的顺序和一致性保持正确。
    2. **数据量过大**
       * 数据量过大时，CDC 需要有效地处理和传输数据，避免网络和存储瓶颈。
    3. **数据丢失**
       * 如果 CDC 进程故障或网络异常，可能导致数据丢失，需要设计可靠的恢复机制。
    4. **数据格式和兼容性**
       * 不同的数据库和 CDC 工具可能使用不同的事件格式，需要进行数据转换和清洗。
### 日志（Logs）
- **日志**是一种用于记录系统中发生的事件的信息。
  - 它提供了关于系统活动的**详细记录**，通常包括：
    * 系统启动时的状态
    * 应用程序的运行情况
    * 用户的操作行为
    * 错误和异常事件
  * 例如：
    * **Web 服务器日志**：记录了用户的访问请求和流量数据。
    * **操作系统日志**：记录了系统启动、应用程序启动和崩溃等事件。
  * **日志数据**是下游数据分析、机器学习和自动化系统的宝贵数据源。
* **常见的日志来源**
![](Data%20Engineer%20Study/%E6%88%AA%E5%B1%8F2025-03-30%20%E4%B8%8B%E5%8D%889.56.10.png)<!-- {"width":485} -->
- **日志的基本信息**
![](Data%20Engineer%20Study/%E6%88%AA%E5%B1%8F2025-03-30%20%E4%B8%8B%E5%8D%889.56.41.png)<!-- {"width":807} -->
- 日志的编码方式
  - 根据用途和存储需求，日志通常采用以下三种编码方式：
  1. 二进制编码日志
     * 使用自定义的**紧凑格式**存储数据，效率高，节省空间。
       * 主要用于数据库日志等场景。
     * **示例**：数据库事务日志、Kafka 内部日志。
     - **优点**：
       * 读写速度快
       * 存储占用少
     - **缺点**：
       * 不易于直接读取和分析
       * 需要专用工具进行解析
  2. 半结构化日志
     * 以 **JSON** 或 **XML** 等格式存储，方便机器读取和解析。
       * 是现代日志系统中最常见的形式。
     * **优点**：
       * 结构清晰，易于分析
       * 可移植性强，适合跨系统传输
     - **缺点**：
       * 文件较大，存储成本较高
       * 解析速度慢于二进制编码
  3. 纯文本（非结构化）日志
     * 以纯文本形式存储，类似于程序控制台的输出内容。
       * 通常用于调试和故障排查。
     * **优点**：
       * 简单直观
       * 易于读取
     - **缺点**：
       * 缺乏统一结构，难以解析和分析
       * 需要使用正则表达式或文本处理工具进行解析
* 日志的分辨率与日志级别
  - 日志分辨率（Resolution）
    * **日志分辨率**指的是日志记录的详细程度。
    * 一些日志记录详细的事件信息，例如数据库日志，可用于还原数据状态。
    * 其他日志可能只记录事件的摘要，以减少存储量。
![](Data%20Engineer%20Study/%E6%88%AA%E5%B1%8F2025-03-30%20%E4%B8%8B%E5%8D%889.59.52.png)<!-- {"width":656} -->
- **日志的延迟：批量与实时**
  - 根据生成和处理的方式，日志可以分为以下两种：
  1. 批量日志（Batch Logs）
     * 日志被**连续写入文件**，定期批量处理和分析。
     * 常用于存储系统事件、错误信息等。
     - **示例**：
       * 每小时收集一次服务器的访问日志，并上传到数据仓库进行分析。
  2. 实时日志（Real-Time Logs）
     * 日志以**事件流**的形式直接发送到消息系统（如 **Kafka** 或 **Pulsar**）。
       * 用于实时监控、告警和事件驱动的系统。
     - **示例**：
       * 电商平台监控用户下单行为，并在订单异常时立即触发告警。
### 数据库日志（Database Logs）
* **数据库日志**在数据库管理中起着至关重要的作用，因此值得深入了解。
  * 在数据库中，一种常见的日志类型是**预写日志（Write-Ahead Logs, WAL）**。
  * 这些日志通常以**二进制文件**的形式存储，采用数据库原生的格式。
* 数据库日志的作用
  1. 数据可靠性和可恢复性
     * **预写日志（WAL）**是数据库用来确保数据一致性和可靠性的核心机制。
       * 当数据库服务器接收到写入或更新请求时，**先将操作记录写入日志**，然后再执行实际的数据库写入操作。
       * **只有在日志写入成功后**，数据库才会向客户端发送确认响应。
     - **作用：**
       * 如果服务器在操作过程中崩溃或发生故障，数据库可以通过日志重新执行未完成的操作，恢复到崩溃前的一致状态。
       * 确保即使在异常情况下，数据也不会丢失。
  2. 支持事务一致性
     * 数据库日志记录了每一个事务的操作，包括**插入**、**更新**和**删除**。
     * 在事务提交前，所有的更改都会写入日志，并在发生异常时通过日志进行**回滚（Rollback）或重做（Redo）**。
  3. 支持数据复制和同步
     * 数据库日志也是**变更数据捕获（CDC）**的重要数据源。
     * 数据工程师可以读取这些日志，将数据变更事件转换为数据流，发送至消息队列或其他系统。
     * 实现**实时数据同步**或**数据仓库更新**。
* 数据库日志的工作原理
  - 在数据库中，写入数据通常遵循以下流程：
    1. **写入日志**
       * 数据库接收到写入请求。
       * 将请求的所有操作记录写入**预写日志（WAL）**。
    2. **确认请求**
       * 数据库确认日志写入成功后，向客户端返回成功响应。
    3. **数据写入**
       * 数据库异步地将数据写入存储系统。
    4. **数据恢复（在异常情况下）**
       * 如果系统崩溃，重启时会根据 WAL 中的记录执行**Redo**操作，将未完成的事务重新应用到数据库中。
* **数据库日志的类型**
![](Data%20Engineer%20Study/%E6%88%AA%E5%B1%8F2025-03-30%20%E4%B8%8B%E5%8D%8810.04.07.png)<!-- {"width":787} -->
- 数据库日志在数据工程中的应用
  - 在数据工程场景中，数据库日志有广泛的应用：
  1. 数据复制与同步
     * 使用 **CDC** 工具（如 **Debezium**、**Maxwell**）从数据库日志中捕获变更事件。
     * 将数据变更事件推送到 **Kafka** 或 **Pulsar** 等消息系统，供下游系统使用。
  2. 实时分析和监控
     * 使用数据库日志监控异常行为，例如检测数据库的异常写入或数据泄漏。
     * 构建**实时数据分析系统**，实现秒级的数据洞察。
  3. 故障恢复和数据回滚
     * 在数据库崩溃后，使用 WAL 进行数据恢复，确保数据完整性。
     * 如果用户误操作导致数据丢失或错误，可以通过日志回滚数据到某个特定时间点。
  4. 事务追踪和审计
     * 使用审计日志记录用户的数据库操作，满足合规性要求。
     * 金融机构和医疗行业常利用日志进行事务追踪和事件重现。
### CRUD
- **CRUD** 是 **Create（创建）、Read（读取）、Update（更新）、Delete（删除）** 的缩写，是一种常见的**事务操作模式**，用于在数据库中执行基础的持久化数据操作。
  - CRUD 模式是应用程序用来**存储和管理数据**的基础。无论数据存储在哪种类型的数据库中，CRUD 操作始终适用。
- CRUD 的重要性
  1. **数据管理的基础**
     * CRUD 是所有数据库管理系统（如 MySQL、PostgreSQL、MongoDB）中最基本的操作。
  2. **API 的核心功能**
     * 在 RESTful API 中，CRUD 操作通常映射到 HTTP 请求：
     * **POST** → Create
     * **GET** → Read
     * **PUT/PATCH** → Update
     * **DELETE** → Delete
  3. **事务性保障**
     * 在执行 CRUD 操作时，数据库通常会提供**事务支持**，确保数据的一致性和完整性。
* **CRUD 数据提取的方式**
  1. 基于快照的提取（Snapshot-Based Extraction）
     * **方式**：定期从数据库中提取当前数据的完整快照。
     * **特点**：简单直观，适合静态分析和周期性报表生成。
     * **缺点**：无法提供实时数据，数据延迟较高。
  2. 基于事件的提取（Event-Based Extraction）
     * **方式**：使用 **CDC（Change Data Capture）** 捕捉数据库中的 CRUD 事件。
     * **特点**：能够实时捕捉数据变更，适用于实时分析和事件驱动的系统。
     * **优点**：提供完整的变更历史，便于追踪数据的演变。
### Insert-Only
- **Insert-Only 模式**是一种在数据库中直接保留数据历史的设计方法。
  - 与传统的 CRUD 模式（**Create、Read、Update、Delete**）不同，**Insert-Only** 不会更新或删除现有数据，而是选择**插入一条新记录**，并通过时间戳（created_timestamp）记录数据的创建时间
- **Insert-Only 模式的工作原理**
  - 当用户地址发生变化时，不会覆盖原记录。
  * 而是直接插入一条新的地址记录，同时保留旧的地址记录。
  * 要查询最新的地址信息，只需要根据 Customer_ID 查找**最新的时间戳**。
* Insert-Only 模式的优势
  1. **数据历史追踪**
     * 保留完整的数据变更历史，便于审计和回溯。
     * 特别适合需要保留用户地址变更记录或银行账户变动的场景。
  2. **避免数据丢失**
     * 由于不覆盖原有数据，即便发生误操作，也能通过历史记录恢复数据。
  3. **方便数据分析**
     * 可基于历史数据分析用户行为趋势，例如地址迁移频率或客户生命周期分析。
  4. **增强业务透明度**
     * 提供详细的变更记录，方便对数据异常进行溯源和调查。
![](Data%20Engineer%20Study/%E6%88%AA%E5%B1%8F2025-04-01%20%E4%B8%8A%E5%8D%8811.40.27.png)<!-- {"width":551} -->
- **Insert-Only 模式的劣势**
  1. 数据量增长过快
     * 由于每次数据变更都会插入一条新记录，表中的数据量会迅速增长。
     * 数据量的增加会导致存储成本上升，并影响查询性能。
     * **解决方法**：
       * 定期清理旧数据。
       * 使用**数据归档**策略，将历史数据迁移到数据湖或冷存储。
       * 设置**保留策略**，例如只保留最近的 N 条记录或特定时间范围内的数据。
  2. 查询性能下降
     * 获取最新数据时，通常需要执行 MAX(Created_Timestamp) 操作。
     * 如果某个 Customer_ID 关联了成千上万条记录，查询成本会很高。
     * **解决方法**：
       * 使用**索引**优化 Created_Timestamp 的查询性能。
       * 创建**物化视图**或维护一张当前数据的快照表，避免每次查询都扫描所有数据。
* **Insert-Only 在 ETL 中的应用**
  * ETL Insert-Only 模式的工作原理
    * **源数据表**中可能采用 CRUD 模式，每次更新数据时覆盖原有数据。
    * 在数据提取阶段，ETL 工具会检测到数据的变化。
    * 数据管道将这些变化以 Insert-Only 的方式写入**目标数据仓库**中。
    * 数据分析师可以在数据仓库中进行历史数据分析，了解数据的演变过程。
### **Messages and Streams**
- 在**事件驱动架构（Event-Driven Architecture）**中，你会经常遇到两个相关的术语：
  * **消息队列（Message Queue）**
  * **数据流（Stream）**
  - 虽然这两个概念有时会被互换使用，但它们之间存在**关键的区别**。了解它们的定义和差异对于理解数据工程生命周期中的各种技术和实践非常重要。
- 什么是消息（Message）？
  - **消息**是指在两个或多个系统之间传递的**原始数据**。
    - IoT 设备 → 消息队列 → 处理服务 → 执行动作 → 消息移除
  - 工作原理
    * **系统 1** 将消息发送到 **系统 2**。
    * 这些系统可能是：
      * 不同的**微服务**
      * **服务器**到**无服务器函数（Serverless Function）**
    * 消息通常通过**消息队列**进行传递。
  - **消息队列的特性**：
    * 消息从发布者（Publisher）发送到消费者（Consumer）。
    * 一旦消息被消费并处理后，它会从队列中**移除**。
    * 每个消息是**独立且一次性**的事件。
  - **示例场景**：
    * **IoT 设备**每隔一分钟发送一个温度读数至消息队列。
    * 一个服务读取该消息，判断是否需要开启或关闭暖气。
    * 服务执行相应操作后，消息被标记为已处理并从队列中移除。
- **什么是数据流（Stream）？**
  - 与消息不同，**数据流**是一种**追加写入的事件日志**，记录一系列有序的事件。
    - IoT 设备 → 数据流 → 分析服务 → 趋势分析 → 监控服务 → 异常告警
  - 工作原理
    * 数据流中的事件会按照**时间戳**或**唯一 ID**排序。
    * **事件不会被删除**，而是保留在流中。
    * 数据通常会存储在**事件流平台**中，例如 **Apache Kafka** 或 **Apache Pulsar**。
  - **数据流的特性**：
    * **追加写入**：每个事件都会被追加到流的末尾。
    * **长时间存储**：事件通常会保留几周甚至几个月，以便后续分析和重放。
    * **事件回溯**：可以回滚到特定时间点，重放历史数据。
    * **多次消费**：不同的消费者可以读取相同的事件，用于不同的用途。
  - **示例场景**：
    * **IoT 设备**不断将温度读数写入数据流。
    * 数据分析服务可以使用这些数据生成温度趋势图。
    * 另一项监控服务会在检测到异常温度时发送告警。
![](Data%20Engineer%20Study/%E6%88%AA%E5%B1%8F2025-04-01%20%E4%B8%8A%E5%8D%8811.46.16.png)<!-- {"width":656} -->
- 结合使用消息和数据流
  - 在许多场景中，**消息队列**和**数据流**会结合使用。
  - 场景示例：智能家居温控系统
    1. **消息传递阶段**
       * 温控系统的 IoT 设备每隔 10 秒发送一次当前温度数据到消息队列。
       * 一个控制服务读取消息并决定是否需要打开或关闭暖气。
       * 处理完成后，消息会从消息队列中删除。
    2. **数据流记录阶段**
       * 同时，温控系统会将所有温度数据写入数据流中。
       * 数据流保存这些数据，供后续的温度趋势分析和异常检测。
    3. **数据分析阶段**
       * 数据分析服务读取数据流，生成温度变化趋势图。
       * 当检测到异常温度时，系统会触发警报并通知用户。
### 时间类型
- 在数据摄取（Data Ingestion）过程中，**时间**是一个至关重要的概念。
  - 尤其在**数据流处理（Streaming）的场景中，数据被视为连续生成**，并且通常需要在产生后尽快被消费。
  - 因此，理解不同类型的时间对于数据准确性和处理效率至关重要。
- 在数据摄取和处理的生命周期中，主要有以下三种类型的时间：
  * **事件时间（Event Time）**
  * **摄取时间（Ingestion Time）**
  * **处理时间（Process Time）**
1. 事件时间（Event Time）
   - **事件时间**是指事件在**源系统中生成的时间**，通常由事件本身携带的**时间戳**表示。
   - 特点
     * 记录事件发生的实际时间。
     * 适用于需要精确分析和回溯的场景。
     * 数据通常带有一个 event_time 字段。
   - 示例场景
     * 用户在电商平台下单的时间。
     * IoT 设备记录温度的时间。
     * 银行交易的时间戳。
   * 注意事项
     * **事件时间可能延迟**：在网络不稳定或系统故障时，事件数据可能会延迟到达。
     * **必须记录事件时间**：即使数据在不同阶段有不同的延迟，事件时间始终表示事件的真实发生时间。
2. 摄取时间（Ingestion Time）
   - **摄取时间**是指事件数据被**从源系统摄取到数据存储或消息队列**的时间。
   - 特点
     * 反映数据首次进入数据处理系统的时间。
     * 常用于监控数据流的延迟。
     * 数据通常带有一个 ingestion_time 字段。
   - 示例场景
     * 数据进入 Apache Kafka 的时间。
     * 数据存储到 Amazon S3 的时间。
     * 数据被写入数据库的时间。
   * 注意事项
     * **摄取时间 ≠ 事件时间**：摄取时间通常比事件时间晚，因为存在网络延迟、缓存或其他中间环节。
     * **需要监控延迟**：如果摄取时间和事件时间之间的差距过大，可能需要优化数据管道。
3. 处理时间（Process Time）
   - **处理时间**是指数据在**数据处理系统中执行转换或计算**的时间。
   - 特点
     * 数据在摄取后并不会立刻被处理，处理时间可能是秒、分钟甚至几小时后。
     * 主要衡量数据处理的效率和延迟。
     * 数据通常带有一个 process_time 字段。
   - 示例场景
     * 数据进入 Spark Streaming 进行转换的时间。
     * 数据在数据仓库中执行聚合计算的时间。
     * 数据写入目标存储的时间。
* 为什么需要记录这些时间？
  * 在实际场景中，记录这三类时间有以下几个重要用途：
  1. 数据延迟监控
     * 通过对比 **事件时间** 和 **摄取时间**，可以监控数据的摄取延迟。
     * 通过对比 **摄取时间** 和 **处理时间**，可以评估数据的处理延迟。
  2. 数据准确性分析
     * 如果事件时间和处理时间存在较大差异，可能导致分析结果不准确。
     * 特别是在金融交易或物联网监控等场景中，精确的事件时间至关重要。
  3. 故障排查和回溯
     * 如果某个数据处理任务出现异常，可以通过时间戳追踪数据流转的全过程。
  4. 确定窗口处理策略
     * 在流处理系统中（如 Apache Flink、Spark Streaming），事件时间通常用于**窗口操作**。
     * 例如：按事件时间划分 5 分钟的窗口，计算每个窗口的销售总额。
![](Data%20Engineer%20Study/%E6%88%AA%E5%B1%8F2025-04-01%20%E4%B8%8A%E5%8D%8811.52.40.png)
### 源系统的实际细节
- 本节将探讨与现代源系统交互时需要了解的**实际细节**。
  - 我们将深入了解在日常工作中常见的数据库、API 以及其他相关方面的内容。
  - 这些信息比之前讨论的概念性内容具有**更短的时效性**，因为流行的 API 框架、数据库技术等都会迅速变化。
- 为什么了解源系统的实际细节很重要？
  - 尽管技术在不断更新，但作为数据工程师，了解这些基础知识是**必要的能力**。
  - 它们帮助你在与源系统交互时更高效地：
    * 提取数据
    * 管理数据流
    * 解决数据摄取中的问题
    * 优化数据处理性能
  - 但仅仅掌握基础知识还不够。由于技术发展迅速，我们建议你：
    * **定期阅读相关文档和行业动态**，了解最新的数据库和 API 更新。
    * **参与开源社区**，关注实际项目中的问题和解决方案。
    * **动手实践**，在真实项目中不断积累经验。
### Databases
- 理解数据库技术的主要考量因素
  - 在了解具体的数据库技术之前，先了解一些在各种数据库中都会涉及的核心概念：
1. 数据库管理系统（Database Management System, DBMS）
   - **数据库管理系统**是用于**存储**和**提供数据服务**的软件系统。
   - 它包括以下主要组件：
     * **存储引擎**：负责将数据存储在磁盘或内存中。
     * **查询优化器**：优化 SQL 查询，确保查询执行效率最高。
     * **灾难恢复**：提供备份、恢复和容灾功能，确保数据安全性。
2. 数据查找（Lookups）
   - 数据库如何**查找和检索数据**是性能的关键因素。
     * **索引**：数据库通过索引加快数据查找速度。
       * 了解数据库是否支持索引以及如何设计和维护索引至关重要。
     * **常见的索引类型**：
       * **B-Tree 索引**：适用于范围查询和排序。
       * **LSM-Tree（Log-Structured Merge Tree）**：在写入密集型场景中表现良好，例如 NoSQL 数据库。
3. 查询优化器（Query Optimizer）
   - **查询优化器**根据数据量、索引、统计信息等因素，自动选择最佳的执行计划。
     * 数据工程师应了解优化器的特性，学会通过 EXPLAIN 语句分析 SQL 查询的执行计划。
     * 一些数据库提供**手动调优**的功能，允许数据工程师根据场景调整查询计划。
4. 扩展性和分布式架构（Scaling and Distribution）
   - 数据库在数据量增长和查询请求增多时，需要支持**横向扩展**或**纵向扩展**。
     * **横向扩展（Horizontal Scaling）**：通过增加数据库节点分担负载（如 NoSQL 数据库）
     * **纵向扩展（Vertical Scaling）**：通过增加单个服务器的资源（如 CPU、内存）提升性能
   - **示例**：
     * **MongoDB** 使用分片（Sharding）进行横向扩展。
     * **Amazon RDS** 提供纵向扩展功能，通过增加实例规格提升性能。
5. 数据建模模式（Modeling Patterns）
   - 不同的数据库采用不同的数据建模方式：
     * **关系型数据库（RDBMS）**：通常使用**数据规范化**（Normalization）将数据拆分成多张表，减少数据冗余。
     * **NoSQL 数据库**：经常采用**宽表**或**嵌套文档**的形式存储数据，优化特定查询场景。
6. CRUD 操作
   - **CRUD**（Create、Read、Update、Delete）是数据库中执行的基本操作。
     * **关系型数据库**：通常通过 SQL 语句执行 CRUD 操作。
     * **NoSQL 数据库**：使用 API 或特定的查询语言（如 MongoDB 的 BSON 查询）执行 CRUD 操作。
7. 数据一致性（Consistency）
   - 数据库的**一致性模型**决定了在不同场景下数据的一致性保障程度。
     * **强一致性（Strong Consistency）**：确保所有读写操作返回最新的数据（如 SQL 数据库）。
     * **最终一致性（Eventual Consistency）**：允许短暂的数据不一致，最终达到一致状态（如 DynamoDB）。
     * **可选一致性模式**：某些数据库支持选择不同级别的一致性，以在性能和一致性之间做出权衡。
- **数据库的主要类型**
  1. **关系型数据库（Relational Database）**
     * 采用表格存储数据，使用 SQL 查询数据。
     * 适用于具有复杂关系的结构化数据。
     * **示例**：MySQL、PostgreSQL、Oracle、SQL Server。
  2. **非关系型数据库（NoSQL Database）**
     * 提供多种数据模型，包括文档存储、键值存储和图数据库。
     * 适用于灵活的数据存储和高并发场景。
     * **示例**：MongoDB、Cassandra、DynamoDB、Neo4j。
- **关系型数据库的基本概念**
  1. 表和关系
     * **关系型数据库**将数据存储在**表格（Table）**中。
       * 每张表由**行（Row）**和**列（Column）**组成。
       * **行**代表一条记录，也称为**关系（Relation）**。
       * **列**表示特定字段，每个字段存储特定类型的数据（如字符串、整数或浮点数）。
       * 在本书中，术语 **“列”** 和 **“字段”** 可以互换使用。
  2. 主键和索引
     * **主键（Primary Key）**：
       * 表中的某个列或列组合，用于唯一标识每一行数据。
       * 例如，在客户表中 Customer_ID 可以作为主键。
     * **索引（Index）**：
       * 索引加速数据的查找和读取操作。
       * 通常主键会自动创建索引，但也可以为其他列创建索引以优化查询性能。
  3. 外键和数据关联
     * **外键（Foreign Key）**：
       * 外键是表中的一个字段，它引用另一个表的主键，用于建立表与表之间的关系。
     * **数据关联**：
       * 通过外键，可以执行跨表查询（如 JOIN）来获取关联数据。
       * 通过外键，数据库可以保证数据的完整性，防止删除关联数据时出现数据不一致。
* 数据规范化（Normalization）
  * **数据规范化**是一种数据库设计策略，旨在消除数据冗余，确保数据一致性。
  * 通过规范化，将数据拆分为多个表，减少重复存储，并确保数据更新时不会引发数据不一致的情况。
* 非关系型数据库：NoSQL
  * 尽管**关系型数据库（RDBMS）在许多场景中表现出色，但它并不是万能的解决方案**。
    * 很多团队在项目初期选择关系型数据库，认为它是一种通用工具，可以满足所有需求。
    * 然而，随着数据量的增长和查询需求的复杂化，关系型数据库的性能往往会**崩溃**，成为系统的瓶颈。
    * 在这种情况下，使用一种更适合特定工作负载的数据库就显得尤为重要。
    * 这时，**非关系型数据库（NoSQL）**便成为了一个理想的选择。
  * 什么是 NoSQL？
    * **NoSQL** 的全称是 **“Not Only SQL”**，它是一类**抛弃了关系型数据库范式**的数据库。
  * NoSQL 数据库的特点
    * **高性能**：通过去除关系型数据库的严格约束，实现更高的读写速度。
    * **横向扩展**：支持分布式架构，可以通过增加节点轻松扩展。
    * **灵活的模式**：通常没有固定的表结构，允许存储半结构化或非结构化数据。
    * **弱一致性**：为了提升性能，许多 NoSQL 数据库采用**最终一致性**而非强一致性。
  - 但与此同时，NoSQL 数据库也有一些**权衡**：
    * **放弃了强一致性**：许多 NoSQL 数据库不提供像关系型数据库那样的强一致性保障。
    * **不支持复杂的关联查询**：缺少 JOIN 等功能，查询需要依靠应用层逻辑或数据冗余。
    * **缺乏标准化**：不同的 NoSQL 数据库设计差异较大，迁移成本较高。
![](Data%20Engineer%20Study/%E6%88%AA%E5%B1%8F2025-04-01%20%E4%B8%8B%E5%8D%8812.26.00.png)
- NoSQL 数据库的实际场景
  1. 键值数据库
     * **场景**：需要快速读写的场景，如缓存、会话存储或实时数据。
     * **示例**：使用 Redis 作为电商平台的购物车缓存，以便快速存取用户的购物车数据。
  2. 文档数据库
     * **场景**：需要存储和查询复杂的 JSON 数据，且数据结构经常变化。
     * **示例**：使用 MongoDB 存储用户信息、订单记录等非结构化数据。
  3. 宽列存储数据库
     * **场景**：处理大规模数据集，适合数据仓库和实时分析。
     * **示例**：使用 Apache Cassandra 存储物流公司的包裹跟踪信息。
  4. 图数据库
     * **场景**：处理高度关联的数据，适用于社交网络、推荐系统和欺诈检测。
     * **示例**：使用 Neo4j 构建社交关系图，分析用户之间的连接关系。
  5. 搜索引擎数据库
     * **场景**：需要快速全文检索的场景，例如日志分析和异常检测。
     * **示例**：使用 Elasticsearch 分析电商平台的用户搜索行为。
  6. 时序数据库
     * **场景**：监控设备状态、分析传感器数据和记录金融市场数据。
     * **示例**：使用 InfluxDB 监控数据中心的服务器 CPU 使用率。
- 键值存储（Key-Value Stores）
  - **键值存储（Key-Value Store）是一种非关系型数据库，它通过一个唯一的键（Key）来检索对应的值（Value）**。
  - 这种存储方式类似于编程语言中的**哈希表（Hash Map）或字典（Dictionary）数据结构，但键值存储数据库通常具备更高的扩展性**和**性能**。
  - 键值存储的工作原理
    - 在键值存储中：
      * **Key**：类似于唯一标识符，用于快速定位数据。
      * **Value**：存储与该键关联的实际数据，数据类型可以是简单字符串、JSON 对象、二进制数据等。
    * **键值存储的特点**
      1. 高速查询
         * 键值存储通过键直接定位数据，查询速度极快。
         * 通常用于**缓存**或需要**低延迟**的场景。
      2. 高并发
         * 能够在高并发环境下保持良好的性能表现。
         * 支持水平扩展，可以通过增加节点来处理大量的请求。
      3. 灵活的数据模型
         * 没有固定的表结构，值可以是简单的文本、JSON、XML 或二进制数据。
         * 非常适合存储**非结构化数据**或**半结构化数据**。
      4. 数据持久化与非持久化
         * **内存型键值存储**（如 Redis）主要用于**缓存**，速度极快但数据不持久。
         * **持久化键值存储**（如 DynamoDB）提供数据持久化，支持高可用性和数据一致性。
    * 键值存储的应用场景
      1. 缓存系统
         * 使用 **Redis** 或 **Memcached** 缓存热门数据，减少对主数据库的访问压力。
         * 例如，将用户的登录信息或产品信息缓存到 Redis 中，以加快页面加载速度。
      2. 会话管理
         * 电商平台或社交媒体应用需要追踪用户的会话状态。
         * 使用键值存储保存用户会话数据，确保快速读取和写入。
      3. 实时数据处理
         * 在物联网（IoT）场景中，传感器产生的大量数据可以存储在键值数据库中，方便快速检索。
         * 使用 **DynamoDB** 等分布式键值存储，确保数据的可靠性和持久性。
      4. 电商购物车管理
         * 用户在购物时，将选中的商品存储到键值数据库中。
         * 使用 cart:user_id 形式的键快速读取和更新购物车数据。
- **文档存储（Document Stores）**
  - **文档存储**是一种特殊类型的**键值存储（Key-Value Store）**，它将数据以**文档（Document）**的形式存储。
  - 在文档存储中，每个文档通常是一个嵌套对象，实际上大多数情况下你可以把它理解为一个 **JSON 对象**。这些文档存储在**集合（Collection）中，并通过键（Key）进行检索。集合在文档存储中类似于关系型数据库中的表（Table）**。
  - 文档存储的特点
    1. 无模式存储
       * 文档存储数据库通常不需要严格的表结构（Schema-Free），即数据的模式是**灵活可变的**。
       * 你可以在同一个集合中存储不同结构的文档，这种灵活性非常适合快速迭代和开发。
    2. 嵌套数据结构
       * 支持存储嵌套的对象和数组，类似于 JSON 或 BSON（MongoDB 的二进制 JSON 格式）。
       * 数据存储在一个文档中，可以避免频繁的 JOIN 查询。
    3. 不支持 JOIN
       * **文档存储不支持关系型数据库中的 JOIN 操作**。
       * 如果需要从不同集合中关联数据，需要在**应用层手动执行关联**或存储冗余数据。
  - 数据一致性与 ACID
    - 与关系型数据库不同，大多数文档存储数据库**不完全支持 ACID**（原子性、一致性、隔离性、持久性）。
      * **最终一致性（Eventual Consistency）**：许多文档存储系统在分布式环境中提供最终一致性。
      * **事务支持**：某些文档存储（如 MongoDB）提供**多文档事务**，以满足数据一致性要求。
  * 索引与查询
    * **索引（Index）**：文档存储数据库通常支持在特定字段上创建索引，以加快查询速度。
    * **灵活查询**：支持基于字段、嵌套对象或数组的查询。
    * **全文搜索**：某些文档存储（如 Elasticsearch）专门用于全文搜索场景。
  * **文档存储的应用场景**
    1. 用户数据管理
       * 电商平台、社交媒体或应用程序中的用户信息通常以 JSON 形式存储在文档存储中。
       * 支持嵌套数据结构，便于存储用户配置、历史记录等。
    2. 内容管理系统（CMS）
       * 媒体公司可以将文章、评论和多媒体数据存储在文档存储中。
       * 数据结构可以随着业务需求的变化而灵活调整。
    3. 物联网数据
       * 物联网设备产生的传感器数据通常以 JSON 格式发送并存储。
       * 文档存储支持高并发写入和数据的快速读取。
![](Data%20Engineer%20Study/%E6%88%AA%E5%B1%8F2025-04-01%20%E4%B8%8B%E5%8D%8812.42.11.png)<!-- {"width":698} -->
### **宽列存储数据库（Wide-Column Database）**
- **宽列存储数据库**是一种专门针对**大规模数据存储**和**高并发事务处理**优化的 NoSQL 数据库。
- 它以**超低延迟**和**高写入速度**著称，通常支持：
  * **PB 级数据存储**
  * **每秒数百万次请求**
  * **低于 10 毫秒的响应时间**
* 这些特性使宽列存储数据库在以下领域广泛应用：
  * **电商**：处理订单和用户活动数据
  * **金融科技（Fintech）**：管理交易记录和账户数据
  * **广告技术（AdTech）**：实时竞价和广告投放数据处理
  * **物联网（IoT）**：处理海量传感器数据
  * **个性化推荐**：实时用户行为分析
* 宽列存储的工作原理
  - 在宽列存储数据库中，数据以**行（Row）**和**列族（Column Family）**的形式存储。
  - 基本结构
    * **行键（Row Key）**：每一行都有唯一的行键，用于快速定位数据。
    * **列族（Column Family）**：一个列族包含多个列，列族类似于关系型数据库中的表。
    * **列（Column）**：每个列都有一个名称和值，并且可以动态添加。
    * **时间戳（Timestamp）**：记录列的历史版本，有助于数据版本管理。
  * Excample
    * **Row Key**：每个用户有一个唯一的行键 user_123。
    * **列族**：分为 User Info 和 Order Info，分别存储用户信息和订单信息。
    * **动态列**：每个列族下的列是动态创建的，不需要预先定义。
* **宽列存储的特点**
  * 1. 极致的读写性能
    * 宽列存储数据库通过**行键索引**实现数据的快速读写。
    * 通常支持**线性扩展**，可以通过增加节点轻松处理更多的请求。
  2. 单索引查询
     * 主要依靠**行键**进行数据查询。
     * 不支持复杂的多条件查询和 JOIN 操作。
  3. 数据分布与分区
     * 数据通常按照**行键的哈希值**进行分区，实现负载均衡。
     * 选择一个合适的行键非常关键，避免数据倾斜。
  4. 数据版本管理
     * 宽列存储数据库通常支持**多版本数据存储**，可以根据时间戳查询历史版本。
* 宽列存储的应用场景
  1. 电商平台
     * 记录用户的购物车信息、订单状态和浏览记录。
     * 使用宽列存储来快速查询用户数据，实现个性化推荐。
  2. 金融交易系统
     * 记录银行交易和账户活动。
     * 提供实时交易查询，确保交易一致性和低延迟。
  3. 物联网数据管理
     * 处理大量的设备传感器数据，支持实时数据采集和监控。
     * 使用宽列存储存储设备的时间序列数据。
